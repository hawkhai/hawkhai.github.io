---
title : 自动快照存档
---

* TIME: 2023-06-16 14:59:21
* URL: <https://github.com/breezedeus/cnstd>

-----

Skip to content Toggle navigation

[ ](https://github.com/)

[ Sign up
](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-
name%3E%2F%3Crepo-name%3E&source=header-repo)

  * Product 

    * [ Actions Automate any workflow  ](/features/actions)
    * [ Packages Host and manage packages  ](/features/packages)
    * [ Security Find and fix vulnerabilities  ](/features/security)
    * [ Codespaces Instant dev environments  ](/features/codespaces)
    * [ Copilot Write better code with AI  ](/features/copilot)
    * [ Code review Manage code changes  ](/features/code-review)
    * [ Issues Plan and track work  ](/features/issues)
    * [ Discussions Collaborate outside of code  ](/features/discussions)

Explore

    * [ All features ](/features)
    * [ Documentation  ](https://docs.github.com)
    * [ GitHub Skills  ](https://skills.github.com/)
    * [ Blog  ](https://github.blog)

  * Solutions 

For

    * [ Enterprise ](/enterprise)
    * [ Teams ](/team)
    * [ Startups ](/enterprise/startups)
    * [ Education  ](https://education.github.com)

By Solution

    * [ CI/CD & Automation ](/solutions/ci-cd/)
    * [ DevOps  ](https://resources.github.com/devops/)
    * [ DevSecOps  ](https://resources.github.com/devops/fundamentals/devsecops/)

Case Studies

    * [ Customer Stories ](/customer-stories)
    * [ Resources  ](https://resources.github.com/)

  * Open Source 

    * [ GitHub Sponsors Fund open source developers  ](/sponsors)

    * [ The ReadME Project GitHub community articles  ](/readme)

Repositories

    * [ Topics ](/topics)
    * [ Trending ](/trending)
    * [ Collections ](/collections)

  * [Pricing](/pricing)

  * [ ![]() In this repository  All GitHub  ↵ Jump to ↵ ]()

  * No suggested jump to results

  * [ ![]() In this repository  All GitHub  ↵ Jump to ↵ ]()
  * [ ![]() In this user  All GitHub  ↵ Jump to ↵ ]()
  * [ ![]() In this repository  All GitHub  ↵ Jump to ↵ ]()

[ Sign in ](/login?return_to=https%3A%2F%2Fgithub.com%2Fbreezedeus%2Fcnstd)

[ Sign up
](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-
name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=breezedeus%2FCnSTD)

You signed in with another tab or window. [Reload]() to refresh your session.
You signed out in another tab or window. [Reload]() to refresh your session.
You switched accounts on another tab or window. [Reload]() to refresh your
session.

{{ message }}

[ breezedeus ](/breezedeus) / **[CnSTD](/breezedeus/CnSTD) ** Public

  * [ Notifications ](/login?return_to=%2Fbreezedeus%2FCnSTD)
  * [ Fork 82 ](/login?return_to=%2Fbreezedeus%2FCnSTD)
  * [ Star  406 ](/login?return_to=%2Fbreezedeus%2FCnSTD)

CnSTD: 基于 PyTorch/MXNet 的 中文/英文 场景文字检测（Scene Text Detection）Python3 包

[huggingface.co/spaces/breezedeus/cnocr](https://huggingface.co/spaces/breezedeus/cnocr
"https://huggingface.co/spaces/breezedeus/cnocr")

### License

[ Apache-2.0 license ](/breezedeus/CnSTD/blob/master/LICENSE)

[ 406 stars ](/breezedeus/CnSTD/stargazers) [ 82 forks
](/breezedeus/CnSTD/forks)

[ Star  ](/login?return_to=%2Fbreezedeus%2FCnSTD)

[ Notifications ](/login?return_to=%2Fbreezedeus%2FCnSTD)

  * [ Code ](/breezedeus/CnSTD)
  * [ Issues 6 ](/breezedeus/CnSTD/issues)
  * [ Pull requests 0 ](/breezedeus/CnSTD/pulls)
  * [ Actions ](/breezedeus/CnSTD/actions)
  * [ Projects 1 ](/breezedeus/CnSTD/projects)
  * [ Security ](/breezedeus/CnSTD/security)
  * [ Insights ](/breezedeus/CnSTD/pulse)

More

  * [ Code ](/breezedeus/CnSTD)
  * [ Issues ](/breezedeus/CnSTD/issues)
  * [ Pull requests ](/breezedeus/CnSTD/pulls)
  * [ Actions ](/breezedeus/CnSTD/actions)
  * [ Projects ](/breezedeus/CnSTD/projects)
  * [ Security ](/breezedeus/CnSTD/security)
  * [ Insights ](/breezedeus/CnSTD/pulse)

# breezedeus/CnSTD

This commit does not belong to any branch on this repository, and may belong
to a fork outside of the repository.

master

Switch branches/tags

Branches Tags

Could not load branches

Nothing to show

[ {{ refName }} default ](https://github.com/breezedeus/cnstd/tree/{{
urlEncodedRefName }}) [View all branches](/breezedeus/CnSTD/branches)

Could not load tags

Nothing to show

[ {{ refName }} default ](https://github.com/breezedeus/cnstd/tree/{{
urlEncodedRefName }})

[View all tags](/breezedeus/CnSTD/tags)

# Name already in use

A tag already exists with the provided branch name. Many Git commands accept
both tag and branch names, so creating this branch may cause unexpected
behavior. Are you sure you want to create this branch?

Cancel  Create

[ **4** branches ](/breezedeus/CnSTD/branches) [ **10** tags
](/breezedeus/CnSTD/tags)

[ Go to file ](/breezedeus/CnSTD/find/master) Code

  * Local
  * Codespaces

  * [ ](https://docs.github.com/articles/which-remote-url-should-i-use)

Clone

HTTPS  GitHub CLI

Use Git or checkout with SVN using the web URL.

Work fast with our official CLI. [Learn more about the
CLI](https://cli.github.com).

  * [ Open with GitHub Desktop ](https://desktop.github.com)
  * [ Download ZIP ](/breezedeus/CnSTD/archive/refs/heads/master.zip)

#### Sign In Required

Please [sign
in](/codespaces/new?hide_repo_select=true&ref=master&repo=263859918) to use
Codespaces.

#### Launching GitHub Desktop

If nothing happens, [download GitHub Desktop](https://desktop.github.com/) and
try again.

#### Launching GitHub Desktop

If nothing happens, [download GitHub Desktop](https://desktop.github.com/) and
try again.

#### Launching Xcode

If nothing happens, [download Xcode](https://developer.apple.com/xcode/) and
try again.

#### Launching Visual Studio Code

Your codespace will open once ready.

There was a problem preparing your codespace, please try again.

## Latest commit

[ ![@breezedeus](https://avatars.githubusercontent.com/u/6712673?s=48&v=4)
](/breezedeus)

[breezedeus](/breezedeus/CnSTD/commits?author=breezedeus "View all commits by
breezedeus") [Merge pull
request](/breezedeus/CnSTD/commit/a9e1c112dc38e40622802a95711f2aa5f93f471d
"Merge pull request #55 from breezedeus/pytorch

update version") [#55](https://github.com/breezedeus/CnSTD/pull/55) [from
breezedeus/pytorch](/breezedeus/CnSTD/commit/a9e1c112dc38e40622802a95711f2aa5f93f471d
"Merge pull request #55 from breezedeus/pytorch

update version")

…

[ a9e1c11 ](/breezedeus/CnSTD/commit/a9e1c112dc38e40622802a95711f2aa5f93f471d)
[ Feb 19, 2023
](/breezedeus/CnSTD/commit/a9e1c112dc38e40622802a95711f2aa5f93f471d)

[Merge pull
request](/breezedeus/CnSTD/commit/a9e1c112dc38e40622802a95711f2aa5f93f471d)
[#55](https://github.com/breezedeus/CnSTD/pull/55) [from
breezedeus/pytorch](/breezedeus/CnSTD/commit/a9e1c112dc38e40622802a95711f2aa5f93f471d)

    
    
    update version

`a9e1c11`

## Git stats

  * [ **227** commits  ](/breezedeus/CnSTD/commits/master)

## Files

[Permalink](/breezedeus/CnSTD/tree/a9e1c112dc38e40622802a95711f2aa5f93f471d)

Failed to load latest commit information.

Type

Name

Latest commit message

Commit time

[cnstd](/breezedeus/CnSTD/tree/master/cnstd "cnstd")

[update
docs](/breezedeus/CnSTD/commit/34e3b4fb16eb5dc1018646253674902590ca94d4
"update docs")

February 19, 2023 11:09

[docs](/breezedeus/CnSTD/tree/master/docs "docs")

[add logo
img](/breezedeus/CnSTD/commit/8d2782a33370e1aa1b72ccbca3bee980d308bd43 "add
logo img")

July 20, 2022 09:37

[examples](/breezedeus/CnSTD/tree/master/examples "examples")

[update doc](/breezedeus/CnSTD/commit/323e6fc05f5fbfde6c9b4f8bf5373150d2c6f659
"update doc")

February 1, 2023 13:04

[scripts](/breezedeus/CnSTD/tree/master/scripts "scripts")

[first detect text boxes, and then crop them to get examples for
cnocr…](/breezedeus/CnSTD/commit/e68c1c673cd9c97960a5a27b219c3b6a8cc8b208
"first detect text boxes, and then crop them to get examples for cnocr
training")

May 27, 2022 17:09

[tests](/breezedeus/CnSTD/tree/master/tests "tests")

[optimize box
sorting](/breezedeus/CnSTD/commit/8b1291b2d9ef091756e576c415bd3d1581300773
"optimize box sorting")

February 18, 2023 23:36

[.gitignore](/breezedeus/CnSTD/blob/master/.gitignore ".gitignore")

[first
commit](/breezedeus/CnSTD/commit/1966bf5153609333657fc3d9ea85e0a3c61c9dd2
"first commit")

May 14, 2020 16:46

[LICENSE](/breezedeus/CnSTD/blob/master/LICENSE "LICENSE")

[add LICENSE
statement](/breezedeus/CnSTD/commit/ed1cc2dd4184509fd401ee86718e20a11207a6ad
"add LICENSE statement")

May 31, 2020 15:00

[Makefile](/breezedeus/CnSTD/blob/master/Makefile "Makefile")

[update
version](/breezedeus/CnSTD/commit/b423ffc592b091e88d32f8611f1349b8912fc16a
"update version")

February 19, 2023 11:30

[README.md](/breezedeus/CnSTD/blob/master/README.md "README.md")

[update
docs](/breezedeus/CnSTD/commit/3079a81964519b9de1d67db1debef537577f7550
"update docs")

February 19, 2023 11:16

[RELEASE.md](/breezedeus/CnSTD/blob/master/RELEASE.md "RELEASE.md")

[update
docs](/breezedeus/CnSTD/commit/34e3b4fb16eb5dc1018646253674902590ca94d4
"update docs")

February 19, 2023 11:09

[gpu.Makefile](/breezedeus/CnSTD/blob/master/gpu.Makefile "gpu.Makefile")

[add configs for
gpu](/breezedeus/CnSTD/commit/19ff64d0a6bcfffa3bef024b8866de0312d8113b "add
configs for gpu")

August 24, 2021 11:05

[label_cn.txt](/breezedeus/CnSTD/blob/master/label_cn.txt "label_cn.txt")

[first commit: dbnet by
pytorch](/breezedeus/CnSTD/commit/56ca1c2b1770d9cc964bc8c4efdfad22f975a1d0
"first commit: dbnet by pytorch")

August 14, 2021 10:13

[requirements.in](/breezedeus/CnSTD/blob/master/requirements.in
"requirements.in")

[update
dependencies](/breezedeus/CnSTD/commit/3709e44985095270855ffe97c49cfc668d99be45
"update dependencies")

October 6, 2022 16:18

[requirements.txt](/breezedeus/CnSTD/blob/master/requirements.txt
"requirements.txt")

[fix and refactor: add cmd `cnstd
layout`](/breezedeus/CnSTD/commit/260d19041cf38ee559145a9cce3c8a7800d01e54
"fix and refactor: add cmd `cnstd layout`")

October 6, 2022 16:17

[setup.py](/breezedeus/CnSTD/blob/master/setup.py "setup.py")

[support yolov7 base model for
mfd](/breezedeus/CnSTD/commit/582d6c8bc3d4fae7d03783a73ea53c19d2184590
"support yolov7 base model for mfd")

February 18, 2023 23:38

View code

CnSTD Update 2023.02.19：发布 V1.2.2 示例 场景文字检测（STD） 数学公式检测（MFD） 版面分析（Layout
Analysis） 安装 已有STD模型 1\. CnSTD 自己训练的模型 2\. 外部模型 使用方法 场景文字检测（STD）
类函数CnStd.detect() 调用示例 识别检测框中的文字（OCR） 数学公式检测（MFD）与 版面分析（Layout Analysis）
类函数LayoutAnalyzer.analyze() 调用示例 脚本使用 STD 预测单个文件或文件夹中所有图片 MFD or Layout
Analysis 预测单个文件 模型训练 模型转存 未来工作 给作者来杯咖啡

##  README.md

[![](/breezedeus/CnSTD/raw/master/docs/logo.png)](/breezedeus/CnSTD/blob/master/docs/logo.png)

[![Downloads](https://camo.githubusercontent.com/bde0fee9414cf5af7f2827dd50f0193146f675047681f325d1515217231b56bb/68747470733a2f2f7374617469632e706570792e746563682f706572736f6e616c697a65642d62616467652f636e7374643f706572696f643d746f74616c26756e6974733d696e7465726e6174696f6e616c5f73797374656d266c6566745f636f6c6f723d677265792672696768745f636f6c6f723d6f72616e6765266c6566745f746578743d446f776e6c6f616473)](https://pepy.tech/project/cnstd)
[![license](https://camo.githubusercontent.com/2d1568c6b6ad2f09cff9ea8f34d166be3d2cc9d49a36347635566b512c02b235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f627265657a65646575732f636e737464)](/breezedeus/CnSTD/blob/master/LICENSE)
[![PyPI
version](https://camo.githubusercontent.com/0582392f36aa186a28b6149f3989869c8aa82688cf7d632aaa5d0b57df56a769/68747470733a2f2f62616467652e667572792e696f2f70792f636e7374642e737667)](https://badge.fury.io/py/cnstd)
[![forks](https://camo.githubusercontent.com/21b13e9e4bf7b34c3eef273903f579b7b90ab65884cd1f64410ad31044a6466c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f627265657a65646575732f636e737464)](https://img.shields.io/github/forks/breezedeus/cnstd)
[![stars](https://camo.githubusercontent.com/f0ec2a0d4b0b917f9b344e2e14f410eeaddbd47cc2929b1d78049f300819cbd9/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f627265657a65646575732f636e737464)](https://github.com/breezedeus/cnocr)
[![last-
releast](https://camo.githubusercontent.com/7c803520fb348f4a6d4a6854531ac2940ea9461bc13f80b4438647dd36e668c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652d646174652f627265657a65646575732f636e7374643f7374796c653d706c6173746963)](https://camo.githubusercontent.com/7c803520fb348f4a6d4a6854531ac2940ea9461bc13f80b4438647dd36e668c0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652d646174652f627265657a65646575732f636e7374643f7374796c653d706c6173746963)
[![last-
commit](https://camo.githubusercontent.com/7fa03ec2b4324fb923840edf079e2caddd94faca25eb15331a48fe6030919765/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f627265657a65646575732f636e737464)](https://camo.githubusercontent.com/7fa03ec2b4324fb923840edf079e2caddd94faca25eb15331a48fe6030919765/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f627265657a65646575732f636e737464)
[![Twitter](https://camo.githubusercontent.com/440cc3758750a2f3431371e7ffe6e06a87b403da6ed5232bf09aeebc29628351/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c3f75726c3d6874747073253341253246253246747769747465722e636f6d253246627265657a6564657573)](https://twitter.com/breezedeus)

# CnSTD

# Update 2023.02.19：发布 V1.2.2

主要变更：

  * MFD训练了参数更多精度更高的模型，供 [P2T网页版](https://p2t.behye.com) 使用。
  * 优化了检测出的boxes的排序算法，使得boxes的顺序更加符合人类的阅读习惯。

了解更多：[RELEASE.md](/breezedeus/CnSTD/blob/master/RELEASE.md) 。

* * *

**CnSTD** 是 **Python 3** 下的 **场景文字检测** （ **Scene Text Detection** ，简称 **STD**
）工具包，支持 **中文** 、 **英文** 等语言的文字检测，自带了多个训练好的检测模型，安装后即可直接使用。 **CnSTD** 自
**V1.2.1** 版本开始，加入了 **数学公式检测** （ **Mathematical Formula Detection** ，简称
**MFD** ）模型，并提供训练好的模型可直接用于检测图片中包含的数学公式（ **行内公式** `embedding` 与 **独立行公式**
`isolated` ）。

欢迎扫码加入微信交流群：

[![微信群二维码](https://camo.githubusercontent.com/2d169c943833587392d496c81fde544e2145eb6cbebf9d755a3104d62a6d50e8/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f627265657a65646575732f636e6f63722d77782d71722d636f64652f7265736f6c76652f6d61696e2f77782d71722d636f64652e4a5047)](https://camo.githubusercontent.com/2d169c943833587392d496c81fde544e2145eb6cbebf9d755a3104d62a6d50e8/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f627265657a65646575732f636e6f63722d77782d71722d636f64652f7265736f6c76652f6d61696e2f77782d71722d636f64652e4a5047)

作者也维护 **知识星球** [**CnOCR/CnSTD/P2T私享群**](https://t.zsxq.com/FEYZRJQ)，欢迎加入。
**知识星球私享群** 会陆续发布一些CnOCR/CnSTD/P2T相关的私有资料，包括 **更详细的训练教程** ， **未公开的模型**
，使用过程中遇到的难题解答等。本群也会发布OCR/STD相关的最新研究资料。

自 **V1.0.0** 版本开始， **CnSTD** 从之前基于 MXNet 实现转为基于 **PyTorch** 实现。新模型的训练合并了
**ICPR MTWI 2018** 、 **ICDAR RCTW-17** 和 **ICDAR2019-LSVT** 三个数据集，包括了
**`46447`** 个训练样本，和 **`1534`** 个测试样本。

相较于之前版本， 新版本的变化主要包括：

  * 加入了对 [**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR) 检测模型的支持；
  * 部分调整了检测结果中 `box` 的表达方式，统一为 `4` 个点的坐标值；
  * 修复了已知bugs。

如需要识别文本框中的文字，可以结合 **OCR** 工具包 **[cnocr](https://github.com/breezedeus/cnocr)**
一起使用。

## 示例

### 场景文字检测（STD）

[![STD效果](/breezedeus/CnSTD/raw/master/docs/cases.png)](/breezedeus/CnSTD/blob/master/docs/cases.png)

### 数学公式检测（MFD）

MFD 模型检测图片中包含的数学公式，其中行内的公式检测为 `embedding` 类别，独立行的公式检测为 `isolated`。模型训练使用了英文
[IBEM](https://zenodo.org/record/4757865) 和中文
[CnMFD_Dataset](https://github.com/breezedeus/CnMFD_Dataset) 两个数据集。

[![中文MFD效果](/breezedeus/CnSTD/raw/master/examples/mfd/out-
zh4.jpg)](/breezedeus/CnSTD/blob/master/examples/mfd/out-zh4.jpg)

[![中文MFD效果](/breezedeus/CnSTD/raw/master/examples/mfd/out-
zh5.jpg)](/breezedeus/CnSTD/blob/master/examples/mfd/out-zh5.jpg)

[![英文MFD效果](/breezedeus/CnSTD/raw/master/examples/mfd/out-
en2.jpg)](/breezedeus/CnSTD/blob/master/examples/mfd/out-en2.jpg)

### 版面分析（Layout Analysis）

版面分析模型识别图片中的不同排版元素。模型训练使用的是 [CDLA](https://github.com/buptlihang/CDLA)
数据集。可识别以下10中版面元素：

正文 | 标题 | 图片 | 图片标题 | 表格 | 表格标题 | 页眉 | 页脚 | 注释 | 公式  
---|---|---|---|---|---|---|---|---|---  
Text | Title | Figure | Figure caption | Table | Table caption | Header |
Footer | Reference | Equation  
  
[![版面分析效果](/breezedeus/CnSTD/raw/master/examples/layout/out-
zh.jpg)](/breezedeus/CnSTD/blob/master/examples/layout/out-zh.jpg)

## 安装

嗯，顺利的话很简单（bless）。

    
    
    pip install cnstd

安装速度慢的话，可以指定国内的安装源，如使用豆瓣源：

    
    
    pip install cnstd -i https://pypi.doubanio.com/simple

【注意】：

  * 请使用 **Python3** (3.6以及之后版本应该都行)，没测过Python2下是否ok。
  * 依赖 **opencv** ，所以可能需要额外安装opencv。

## 已有STD模型

CnSTD 从 **V1.2** 开始，可直接使用的模型包含两类：1）CnSTD 自己训练的模型，通常会包含 PyTorch 和 ONNX
版本；2）从其他ocr引擎搬运过来的训练好的外部模型，ONNX化后用于 CnSTD 中。

直接使用的模型都放在 [**cnstd-cnocr-models**](https://huggingface.co/breezedeus/cnstd-
cnocr-models) 项目中，可免费下载使用。

### 1\. CnSTD 自己训练的模型

当前版本（Since **V1.1.0** ）的文字检测模型使用的是
[**DBNet**](https://github.com/MhLiao/DB)，相较于 V0.1 使用的
[PSENet](https://github.com/whai362/PSENet) 模型， DBNet
的检测耗时几乎下降了一个量级，同时检测精度也得到了极大的提升。

目前包含以下已训练好的模型：

模型名称 | 参数规模 | 模型文件大小 | 测试集精度（IoU） | 平均推断耗时  
（秒/张） | 下载方式  
---|---|---|---|---|---  
db_resnet34 | 22.5 M | 86 M | **0.7322** | 3.11 | 自动  
db_resnet18 | 12.3 M | 47 M | 0.7294 | 1.93 | 自动  
db_mobilenet_v3 | 4.2 M | 16 M | **0.7269** | 1.76 | 自动  
db_mobilenet_v3_small | 2.0 M | 7.9 M | 0.7054 | 1.24 | 自动  
db_shufflenet_v2 | 4.7 M | 18 M | 0.7238 | 1.73 | 自动  
**db_shufflenet_v2_small** | 3.0 M | 12 M | 0.7190 | 1.29 | 自动  
db_shufflenet_v2_tiny | **1.9 M** | **7.5 M** | **0.7172** | **1.14** |
[下载链接](https://mp.weixin.qq.com/s/fHPNoGyo72EFApVhEgR6Nw)  
  
> 上表耗时基于本地 Mac 获得，绝对值无太大参考价值，相对值可供参考。IoU的计算方式经过调整，仅相对值可供参考。

相对于两个基于 **ResNet** 的模型，基于 **MobileNet** 和 **ShuffleNet**
的模型体积更小，速度更快，建议在轻量级场景使用。

### 2\. 外部模型

以下模型是 [**PaddleOCR**](https://github.com/PaddlePaddle/PaddleOCR) 中模型的 **ONNX**
版本，所以不会依赖 **PaddlePaddle** 相关工具包，故而也不支持基于这些模型在自己的领域数据上继续精调模型。这些模型支持检测 **竖排文字**
。

`model_name` | PyTorch 版本 | ONNX 版本 | 支持检测的语言 | 模型文件大小  
---|---|---|---|---  
ch_PP-OCRv3_det | X | √ | 简体中问、英文、数字 | 2.3 M  
ch_PP-OCRv2_det | X | √ | 简体中问、英文、数字 | 2.2 M  
en_PP-OCRv3_det | X | √ | **英文** 、数字 | 2.3 M  
  
更多模型可参考
[PaddleOCR/models_list.md](https://github.com/PaddlePaddle/PaddleOCR/blob/release%2F2.5/doc/doc_ch/models_list.md)
。如有其他外语（如日、韩等）检测需求，可在 **知识星球**
[**CnOCR/CnSTD私享群**](https://t.zsxq.com/FEYZRJQ) 中向作者提出建议。

## 使用方法

首次使用 **CnSTD** 时，系统会自动下载zip格式的模型压缩文件，并存放于 `~/.cnstd`目录（Windows下默认路径为
`C:\Users\<username>\AppData\Roaming\cnstd`）。下载速度超快。下载后的zip文件代码会自动对其解压，然后把解压后的模型相关目录放于`~/.cnstd/1.2`目录中。

如果系统无法自动成功下载zip文件，则需要手动从
[百度云盘](https://pan.baidu.com/s/1zDMzArCDrrXHWL0AWxwYQQ?pwd=nstd)（提取码为
`nstd`）下载对应的zip文件并把它存放于 `~/.cnstd/1.2`（Windows下为
`C:\Users\<username>\AppData\Roaming\cnstd\1.2`）目录中。模型也可从 **[cnstd-cnocr-
models](https://huggingface.co/breezedeus/cnstd-cnocr-models)**
中下载。放置好zip文件后，后面的事代码就会自动执行了。

### 场景文字检测（STD）

使用类 `CnStd` 进行场景文字的检测。类 `CnStd` 的初始化函数如下：

    
    
    class CnStd(object):
        """
        场景文字检测器（Scene Text Detection）。虽然名字中有个"Cn"（Chinese），但其实也可以轻松识别英文的。
        """
    
        def __init__(
            self,
            model_name: str = 'ch_PP-OCRv3_det',
            *,
            auto_rotate_whole_image: bool = False,
            rotated_bbox: bool = True,
            context: str = 'cpu',
            model_fp: Optional[str] = None,
            model_backend: str = 'onnx',  # ['pytorch', 'onnx']
            root: Union[str, Path] = data_dir(),
            use_angle_clf: bool = False,
            angle_clf_configs: Optional[dict] = None,
            **kwargs,
        ):

其中的几个参数含义如下：

  * `model_name`: 模型名称，即前面模型表格第一列中的值。默认为 **ch_PP-OCRv3_det** 。

  * `auto_rotate_whole_image`: 是否自动对整张图片进行旋转调整。默认为`False`。

  * `rotated_bbox`: 是否支持检测带角度的文本框；默认为 `True`，表示支持；取值为 `False` 时，只检测水平或垂直的文本。

  * `context`：预测使用的机器资源，可取值为字符串`cpu`、`gpu`、`cuda:0`。

  * `model_fp`: 如果不使用系统自带的模型，可以通过此参数直接指定所使用的模型文件（`.ckpt`文件）。

  * `model_backend` (str): 'pytorch', or 'onnx'。表明预测时是使用 PyTorch 版本模型，还是使用 ONNX 版本模型。 同样的模型，ONNX 版本的预测速度一般是 PyTorch 版本的2倍左右。默认为 `onnx`。

  * `root`: 模型文件所在的根目录。

    * Linux/Mac下默认值为 `~/.cnstd`，表示模型文件所处文件夹类似 `~/.cnstd/1.2/db_shufflenet_v2_small`。
    * Windows下默认值为 `C:\Users\<username>\AppData\Roaming\cnstd`。
  * `use_angle_clf` (bool): 对于检测出的文本框，是否使用角度分类模型进行调整（检测出的文本框可能会存在倒转180度的情况）。默认为 `False`

  * `angle_clf_configs` (dict): 角度分类模型对应的参数取值，主要包含以下值：

    * `model_name`: 模型名称。默认为 'ch_ppocr_mobile_v2.0_cls'
    * `model_fp`: 如果不使用系统自带的模型，可以通过此参数直接指定所使用的模型文件（'.onnx' 文件）。默认为 `None`。具体可参考类 `AngleClassifier` 的说明

每个参数都有默认取值，所以可以不传入任何参数值进行初始化：`std = CnStd()`。

文本检测使用类`CnOcr`的函数 **`detect()`** ，以下是详细说明：

#### 类函数`CnStd.detect()`

    
    
        def detect(
            self,
            img_list: Union[
                str,
                Path,
                Image.Image,
                np.ndarray,
                List[Union[str, Path, Image.Image, np.ndarray]],
            ],
            resized_shape: Union[int, Tuple[int, int]] = (768, 768),
            preserve_aspect_ratio: bool = True,
            min_box_size: int = 8,
            box_score_thresh: float = 0.3,
            batch_size: int = 20,
            **kwargs,
        ) -> Union[Dict[str, Any], List[Dict[str, Any]]]:

**函数说明** ：

函数输入参数包括：

  * `img_list`: 支持对单个图片或者多个图片（列表）的检测。每个值可以是图片路径，或者已经读取进来 `PIL.Image.Image` 或 `np.ndarray`, 格式应该是 `RGB` 3 通道，shape: `(height, width, 3)`, 取值范围：`[0, 255]`。

  * `resized_shape`: `int` or `tuple`, `tuple` 含义为 `(height, width)`, `int` 则表示高宽都为此值；  
检测前，先把原始图片resize到接近此大小（只是接近，未必相等）。默认为 `(768, 768)`。

> Note **（注意）** 这个取值对检测结果的影响较大，可以针对自己的应用多尝试几组值，再选出最优值。例如 `(512, 768)`, `(768,
> 768)`, `(768, 1024)`等。

  * `preserve_aspect_ratio`: 对原始图片 resize 时是否保持高宽比不变。默认为 `True`。

  * `min_box_size`: 过滤掉高度或者宽度小于此值的文本框。默认为 `8`，也即高或者宽小于 `8` 的文本框会被过滤去掉。

  * `box_score_thresh`: 过滤掉得分低于此值的文本框。默认为 `0.3`。

  * `batch_size`: 待处理图片很多时，需要分批处理，每批图片的数量由此参数指定。默认为 `20`。

  * `kwargs`: 保留参数，目前未被使用。

函数输出类型为`list`，其中每个元素是一个字典，对应一张图片的检测结果。字典中包含以下 `keys`：

  * `rotated_angle`: `float`, 整张图片旋转的角度。只有 `auto_rotate_whole_image==True` 才可能非 `0`。

  * `detected_texts`: `list`, 每个元素存储了检测出的一个框的信息，使用词典记录，包括以下几个值：

    * `box`：检测出的文字对应的矩形框；`np.ndarray`, shape: `(4, 2)`，对应 box 4个点的坐标值 `(x, y)`;

    * `score`：得分；`float` 类型；分数越高表示越可靠；

    * `croppped_img`：对应 "box" 中的图片patch（`RGB`格式），会把倾斜的图片旋转为水平。`np.ndarray`类型，`shape: (height, width, 3)`, 取值范围：`[0, 255]`；

    * 示例:
        
                  [{'box': array([[416,  77],
                          [486,  13],
                          [800, 325],
                          [730, 390]], dtype=int32),
            'score': 1.0, 
            'cropped_img': array([[[25, 20, 24],
                                   [26, 21, 25],
                                   [25, 20, 24],
                                  ...,
                                   [11, 11, 13],
                                   [11, 11, 13],
                                   [11, 11, 13]]], dtype=uint8)},
           ...
          ]

#### 调用示例

    
    
    from cnstd import CnStd
    std = CnStd()
    box_info_list = std.detect('examples/taobao.jpg')

或：

    
    
    from PIL import Image
    from cnstd import CnStd
    
    std = CnStd()
    img_fp = 'examples/taobao.jpg'
    img = Image.open(img_fp)
    box_infos = std.detect(img)

### 识别检测框中的文字（OCR）

上面示例识别结果中"cropped_img"对应的值可以直接交由
**[cnocr](https://github.com/breezedeus/cnocr)** 中的 **`CnOcr`** 进行文字识别。如上例可以结合
**`CnOcr`** 进行文字识别：

    
    
    from cnstd import CnStd
    from cnocr import CnOcr
    
    std = CnStd()
    cn_ocr = CnOcr()
    
    box_infos = std.detect('examples/taobao.jpg')
    
    for box_info in box_infos['detected_texts']:
        cropped_img = box_info['cropped_img']
        ocr_res = cn_ocr.ocr_for_single_line(cropped_img)
        print('ocr result: %s' % str(ocr_res))

注：运行上面示例需要先安装 **[cnocr](https://github.com/breezedeus/cnocr)** ：

    
    
    pip install cnocr

### 数学公式检测（MFD）与 版面分析（Layout Analysis）

数学公式检测（MFD）与 版面分析（Layout
Analysis）都是检测图片中感兴趣的元素，它们使用的都是基于YOLOv7的检测架构，在CnSTD都来源于相同的类
`LayoutAnalyzer`，差别只是训练模型使用的数据不同。

> 这两个模型的训练代码在 [yolov7](https://github.com/breezedeus/yolov7) 中（Forked from
> [WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)，感谢原作者。）

类 `LayoutAnalyzer` 的初始化函数如下：

    
    
    class LayoutAnalyzer(object):
        def __init__(
            self,
            model_name: str = 'mfd',  # 'layout' or 'mfd'
            *,
            model_type: str = 'yolov7_tiny',
            model_backend: str = 'pytorch',
            model_fp: Optional[str] = None,
            root: Union[str, Path] = data_dir(),
            device: str = 'cpu',
            **kwargs,
        ):

其中的参数含义如下：

  * `model_name`: 字符串类型，表示模型类型。可选值：'mfd' 表示数学公式检测；'layout' 表示版面分析。默认值：'mfd'

  * `model_type`: 字符串类型，表示模型类型。当前支持 'yolov7_tiny' 和 'yolov7'；默认值：'yolov7_tiny'

  * `model_backend`: 字符串类型，表示backend。当前仅支持: 'pytorch'；默认值：'pytorch'

  * `model_fp`: 字符串类型，表示模型文件的路径。默认值：`None`，表示使用默认的文件路径

  * `root`: 字符串或`Path`类型，表示模型文件所在的根目录。

    * Linux/Mac下默认值为 `~/.cnstd`，表示模型文件所处文件夹类似 `~/.cnstd/1.2/analysis`
    * Windows下默认值为 `C:/Users/<username>/AppData/Roaming/cnstd`。
  * `device`: 字符串类型，表示运行模型的设备，可选值：'cpu' 或 'gpu'；默认值：'cpu'

  * `**kwargs`: 额外的参数。

函数输出结果为一个`list`，其中每个元素表示识别出的版面中的一个元素，包含以下信息：

  * type: 版面元素对应的类型；可选值来自：`self.categories` ;
  * box: 版面元素对应的矩形框；`np.ndarray`, shape: (4, 2)，对应 box 4个点的坐标值 `(x, y)` ;
  * score: 得分，越高表示越可信 。

#### 类函数`LayoutAnalyzer.analyze()`

对指定图片（列表）进行版面分析。

    
    
    def analyze(
        self,
        img_list: Union[
            str,
            Path,
            Image.Image,
            np.ndarray,
            List[Union[str, Path, Image.Image, np.ndarray]],
        ],
        resized_shape: Union[int, Tuple[int, int]] = 700,
        box_margin: int = 2,
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45,
    ) -> Union[List[Dict[str, Any]], List[List[Dict[str, Any]]]]:

**函数说明** ：

函数输入参数包括：

  * `img_list` (str or list): 待识别图片或图片列表；如果是 `np.ndarray`，则应该是shape为 `[H, W, 3]` 的 RGB 格式数组
  * `resized_shape` (int or tuple): (H, W); 把图片resize到此大小再做分析；默认值为 `700`
  * `box_margin` (int): 对识别出的内容框往外扩展的像素大小；默认值为 `2`
  * `conf_threshold` (float): 分数阈值；默认值为 `0.25`
  * `iou_threshold` (float): IOU阈值；默认值为 `0.45`
  * `**kwargs`: 额外的参数。

#### 调用示例

    
    
    from cnstd import LayoutAnalyzer
    img_fp = 'examples/mfd/zh5.jpg'
    analyzer = LayoutAnalyzer('mfd')
    out = analyzer.analyze(img_fp, resized_shape=700)
    print(out)

### 脚本使用

**cnstd** 包含了几个命令行工具，安装 **cnstd** 后即可使用。

#### STD 预测单个文件或文件夹中所有图片

使用命令 **`cnstd predict`** 预测单个文件或文件夹中所有图片，以下是使用说明：

    
    
    (venv) ➜  cnstd git:(master) ✗ cnstd predict -h
    Usage: cnstd predict [OPTIONS]
    
      预测单个文件，或者指定目录下的所有图片
    
    Options:
      -m, --model-name [ch_PP-OCRv2_det|ch_PP-OCRv3_det|db_mobilenet_v3|db_mobilenet_v3_small|db_resnet18|db_resnet34|db_shufflenet_v2|db_shufflenet_v2_small|db_shufflenet_v2_tiny|en_PP-OCRv3_det]
                                      模型名称。默认值为 db_shufflenet_v2_small
      -b, --model-backend [pytorch|onnx]
                                      模型类型。默认值为 `onnx`
      -p, --pretrained-model-fp TEXT  使用训练好的模型。默认为 `None`，表示使用系统自带的预训练模型
      -r, --rotated-bbox              是否检测带角度（非水平和垂直）的文本框。默认为 `True`
      --resized-shape TEXT            格式："height,width";
                                      预测时把图片resize到此大小再进行预测。两个值都需要是32的倍数。默认为
                                      `768,768`
    
      --box-score-thresh FLOAT        检测结果只保留分数大于此值的文本框。默认值为 `0.3`
      --preserve-aspect-ratio BOOLEAN
                                      resize时是否保留图片原始比例。默认值为 `True`
      --context TEXT                  使用cpu还是 `gpu` 运行代码，也可指定为特定gpu，如`cuda:0`。默认为
                                      `cpu`
    
      -i, --img-file-or-dir TEXT      输入图片的文件路径或者指定的文件夹
      -o, --output-dir TEXT           检测结果存放的文件夹。默认为 `./predictions`
      -h, --help                      Show this message and exit.

例如可以使用以下命令对图片 `examples/taobao.jpg`进行检测，并把检测结果存放在目录 `outputs`中：

    
    
    cnstd predict -i examples/taobao.jpg -o outputs

具体使用也可参考文件 [Makefile](/breezedeus/CnSTD/blob/master/Makefile) 。

#### MFD or Layout Analysis 预测单个文件

使用命令 **`cnstd analyze`** 获得单个文件的 MFD 或者 Layout Analysis 结果，以下是使用说明：

    
    
    (venv) ➜  cnstd git:(master) ✗ cnstd analyze -h
    Usage: cnstd analyze [OPTIONS]
    
      对给定图片进行 MFD 或者 版面分析。
    
    Options:
      -m, --model-name [mfd|layout]   模型类型。`mfd` 表示数学公式检测，`layout`
                                      表示版面分析；默认为：`mfd`
      -t, --model-type TEXT           模型类型。当前支持 [`yolov7_tiny`, `yolov7`]
      -b, --model-backend [pytorch|onnx]
                                      模型后端架构。当前仅支持 `pytorch`
      -p, --model-fp TEXT             使用训练好的模型。默认为 `None`，表示使用系统自带的预训练模型
      --device TEXT                   cuda device, i.e. 0 or 0,1,2,3 or cpu
      -i, --img-fp TEXT               待分析的图片路径或图片目录
      -o, --output-fp TEXT            分析结果输出的图片路径。默认为 `None`，会存储在当前文件夹，文件名称为输入文件名称
                                      前面增加`out-`；如输入文件名为 `img.jpg`, 输出文件名即为 `out-
                                      img.jpg`；如果输入为目录，则此路径也应该是一个目录，会将输出文件存储在此目录下
      --resized-shape INTEGER         分析时把图片resize到此大小再进行。默认为 `700`
      --conf-thresh FLOAT             Confidence Threshold。默认值为 `0.25`
      --iou-thresh FLOAT              IOU threshold for NMS。默认值为 `0.45`
      -h, --help                      Show this message and exit.

例如可以使用以下命令对图片 `examples/mfd/zh.jpg` 进行 MFD，并把检测结果存放在文件 `out-zh.jpg` 中：

    
    
    (venv) ➜  cnstd analyze -m mfd --conf-thresh 0.25 --resized-shape 800 -i examples/mfd/zh.jpg -o out-zh.jpg

具体使用也可参考文件 [Makefile](/breezedeus/CnSTD/blob/master/Makefile) 。

#### 模型训练

使用命令 **`cnstd train`** 训练文本检测模型，以下是使用说明：

    
    
    (venv) ➜  cnstd git:(master) ✗ cnstd train -h
    Usage: cnstd train [OPTIONS]
    
      训练文本检测模型
    
    Options:
      -m, --model-name [db_resnet50|db_resnet34|db_resnet18|db_mobilenet_v3|db_mobilenet_v3_small|db_shufflenet_v2|db_shufflenet_v2_small|db_shufflenet_v2_tiny]
                                      模型名称。默认值为 `db_shufflenet_v2_small`
      -i, --index-dir TEXT            索引文件所在的文件夹，会读取文件夹中的 `train.tsv` 和 `dev.tsv` 文件
                                      [required]
    
      --train-config-fp TEXT          训练使用的json配置文件  [required]
      -r, --resume-from-checkpoint TEXT
                                      恢复此前中断的训练状态，继续训练
      -p, --pretrained-model-fp TEXT  导入的训练好的模型，作为初始模型。优先级低于 "--restore-training-
                                      fp"，当传入"--restore-training-fp"时，此传入失效
    
      -h, --help                      Show this message and exit.

具体使用可参考文件 [Makefile](/breezedeus/CnSTD/blob/master/Makefile) 。

#### 模型转存

训练好的模型会存储训练状态，使用命令 **`cnstd resave`** 去掉与预测无关的数据，降低模型大小。

    
    
    (venv) ➜  cnstd git:(master) ✗ cnstd resave -h
    Usage: cnstd resave [OPTIONS]
    
      训练好的模型会存储训练状态，使用此命令去掉预测时无关的数据，降低模型大小
    
    Options:
      -i, --input-model-fp TEXT   输入的模型文件路径  [required]
      -o, --output-model-fp TEXT  输出的模型文件路径  [required]
      -h, --help                  Show this message and exit.

## 未来工作

  * 进一步精简模型结构，降低模型大小
  * PSENet速度上还是比较慢，尝试更快的STD算法
  * 加入更多的训练数据
  * 加入对外部模型的支持
  * 加入数学公式检测（MFD）与 版面分析（Layout Analysis）模型
  * 加入对文档结构与表格的检测

## 给作者来杯咖啡

开源不易，如果此项目对您有帮助，可以考虑 [给作者来杯咖啡
☕️](https://cnocr.readthedocs.io/zh/latest/buymeacoffee/) 。

* * *

官方代码库：<https://github.com/breezedeus/cnstd>。

## About

CnSTD: 基于 PyTorch/MXNet 的 中文/英文 场景文字检测（Scene Text Detection）Python3 包

[huggingface.co/spaces/breezedeus/cnocr](https://huggingface.co/spaces/breezedeus/cnocr
"https://huggingface.co/spaces/breezedeus/cnocr")

### Topics

[ deep-learning ](/topics/deep-learning "Topic: deep-learning") [ pytorch
](/topics/pytorch "Topic: pytorch") [ object-detection ](/topics/object-
detection "Topic: object-detection") [ text-detection ](/topics/text-detection
"Topic: text-detection") [ math-formula-detection ](/topics/math-formula-
detection "Topic: math-formula-detection")

### Resources

Readme

### License

[ Apache-2.0 license ](/breezedeus/CnSTD/blob/master/LICENSE)

### Stars

[ **406** stars ](/breezedeus/CnSTD/stargazers)

### Watchers

[ **12** watching ](/breezedeus/CnSTD/watchers)

### Forks

[ **82** forks ](/breezedeus/CnSTD/forks)

[ Report repository ](/contact/report-
content?content_url=https%3A%2F%2Fgithub.com%2Fbreezedeus%2FCnSTD&report=breezedeus+%28user%29)

##  [ Releases 10 ](/breezedeus/CnSTD/releases)

[ support yolov7 base model for mfd Latest  Feb 19, 2023
](/breezedeus/CnSTD/releases/tag/v1.2.2)

[ \+ 9 releases ](/breezedeus/CnSTD/releases)

##  [ Packages 0 ](/users/breezedeus/packages?repo_name=CnSTD)

No packages published  

##  [ Used by 35 ](/breezedeus/CnSTD/network/dependents)

[

  * ![@Boluex](https://avatars.githubusercontent.com/u/90112749?s=64&v=4)
  * ![@Boluex](https://avatars.githubusercontent.com/u/90112749?s=64&v=4)
  * ![@csxmli2016](https://avatars.githubusercontent.com/u/26357039?s=64&v=4)
  * ![@Samawia2910](https://avatars.githubusercontent.com/u/81920720?s=64&v=4)
  * ![@heroineyy](https://avatars.githubusercontent.com/u/82981823?s=64&v=4)
  * ![@angry010101](https://avatars.githubusercontent.com/u/24439691?s=64&v=4)
  * ![@martindbp](https://avatars.githubusercontent.com/u/46844406?s=64&v=4)
  * ![@danty111](https://avatars.githubusercontent.com/u/130046493?s=64&v=4)

\+ 27  ](/breezedeus/CnSTD/network/dependents)

## Languages

  * [ Python 99.8% ](/breezedeus/CnSTD/search?l=python)
  * [ Makefile 0.2% ](/breezedeus/CnSTD/search?l=makefile)

## Footer

[ ](https://github.com "GitHub") © 2023 GitHub, Inc.

### Footer navigation

  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com)
  * [Contact GitHub](https://support.github.com?tags=dotcom-footer)
  * [Pricing](https://github.com/pricing)
  * [API](https://docs.github.com)
  * [Training](https://services.github.com)
  * [Blog](https://github.blog)
  * [About](https://github.com/about)

You can’t perform that action at this time.

