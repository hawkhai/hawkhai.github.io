---
title : 自动快照存档
---

* TIME: 2023-08-01 15:44:21
* URL: <https://www.cnblogs.com/knife-rose/p/12107204.html>

-----

  * [ ![博客园Logo](//common.cnblogs.com/logo.svg) ](https://www.cnblogs.com/ "开发者的网上家园")
  * [首页](/)
  * [新闻](https://news.cnblogs.com/)
  * [博问](https://q.cnblogs.com/)
  * [会员](https://cnblogs.vip/)
  * [直播](https://www.cnblogs.com/cmt/p/17588697.html)
  * [闪存](https://ing.cnblogs.com/)
  * [班级](https://edu.cnblogs.com/)

  * ![搜索](//common.cnblogs.com/icons/search.svg) ![搜索](//common.cnblogs.com/icons/enter.svg)
    * ![搜索](//common.cnblogs.com/icons/search.svg)

所有博客

    * ![搜索](//common.cnblogs.com/icons/search.svg)

当前博客

  * [ ![写随笔](//common.cnblogs.com/icons/newpost.svg) ](https://i.cnblogs.com/EditPosts.aspx?opt=1 "写随笔") [ ![我的博客](//common.cnblogs.com/icons/myblog.svg) ](https://passport.cnblogs.com/GetBlogApplyStatus.aspx "我的博客") [ ![短消息](//common.cnblogs.com/icons/message.svg) ](https://msg.cnblogs.com/ "短消息") [ ![简洁模式](//common.cnblogs.com/icons/lite-mode-on.svg) ](javascript:void\(0\) "简洁模式启用，您在访问他人博客时会使用简洁款皮肤展示")

[ ![用户头像](//common.cnblogs.com/icons/avatar-default.svg)
](https://home.cnblogs.com/)

[我的博客](https://passport.cnblogs.com/GetBlogApplyStatus.aspx)
[我的园子](https://home.cnblogs.com/)
[账号设置](https://account.cnblogs.com/settings/account) [ 简洁模式 ![](/images/lite-
mode-check.svg)... ](javascript:void\(0\) "简洁模式会使用简洁款皮肤显示所有博客")
[退出登录](javascript:void\(0\))

[注册](https://account.cnblogs.com/signup) [登录](javascript:void\(0\);)

[![返回主页](/skins/custom/images/logo.gif)](https://www.cnblogs.com/knife-rose/)

# [red](https://www.cnblogs.com/knife-rose/)

## 初相遇，是千山微雨，你是我人间朝夕

  * [ 博客园](https://www.cnblogs.com/) __
  * [ 首页](https://www.cnblogs.com/knife-rose/) __
  * [ 新随笔](https://i.cnblogs.com/EditPosts.aspx?opt=1) __
  * __
  * __
  * [ 管理](https://i.cnblogs.com/) __

随笔 - 69  文章 - 0  评论 - 52  阅读 -  16563

#  [ 线性代数入门 ](https://www.cnblogs.com/knife-rose/p/12107204.html)

## 前言#

某次模拟赛被矩阵虐哭，补一波线代

这篇博客偏入门，概念较多，算法相关较少

大力膜拜3B1B3B1B的[线性代数的本质系列](https://www.bilibili.com/video/av6731067?p=4)

~~（参考资料来源，或者干脆叫观影总结吧……）~~

完全就是观影总结qwqqwq

记号：不作特殊说明，本文中的大写字母均表示某个矩阵，小写字母均表示某个向量

顺便一提，如果对标题分布有点混乱，那么建议看一眼博客右侧的分级目录

## 向量#

### 向量的定义#

高考课本讲的向量大概是：具有长度和方向的箭头[![](https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/w%3D268%3Bg%3D0/sign=17e6afcc780e0cf3a0f749fd327d9522/cc11728b4710b9124f48f420c9fdfc0393452266.jpg)](https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/w%3D268%3Bg%3D0/sign=17e6afcc780e0cf3a0f749fd327d9522/cc11728b4710b9124f48f420c9fdfc0393452266.jpg)

OIOI中向量大部分情况下是：一个n∗1n∗1的矩阵，或者说具有实际含义的一列数字 ⎡⎣⎢⎢⎢⎢⎢⎢⎢⎢114514⎤⎦⎥⎥⎥⎥⎥⎥⎥⎥[114514]

然而实际上只要满足两个事物相加或相乘有意义就可以称之为向量，后面再详细介绍这里

但是这提示了我们：向量相加和相乘在线性代数中起着极为重要的作用

为了更适合入门，我们下面的讲解都会优先考虑几何意义和二维平面

在二维坐标系中，我们定义向量为从原点出发有长度和方向的箭头，虽然理论上向量只由长度和方向决定，与起点无关，但在线代中向量通常以原点为起点

例如：

[![](https://i.loli.net/2019/12/27/5tOIAjGLY4WHpso.png)](https://i.loli.net/2019/12/27/5tOIAjGLY4WHpso.png)

这里有一个我们通常意义上的向量

那么这个箭头和我们的另一种形式：一列数字有什么关联呢？

我们发现一个向量坐标由一对数字构成，这对数字指引你如何从原点（它的起点）出发，到达它的尖端

如上图中，我们可以通过尖端BB的坐标(3,2)(3,2)了解到，我们可以先由原点向xx轴正方向走33个单位长度，再向yy轴走22个单位长度得到

如果我们规定原点是一切向量的起点，那么只要一对数字就可以唯一确定一个二维向量

上图中的箭头可以表示为[32][32] 为了与坐标区分，我们采用竖写加方括号

我们应该可以脑补出三维的场景，这里我就不画图了 ~~我实在画不出来了~~

### 向量加法#

[![](https://i.loli.net/2019/12/27/xdqhwQVTZnrvJpc.png)](https://i.loli.net/2019/12/27/xdqhwQVTZnrvJpc.png)

如图地我们由两个向量uu和vv

对于求出w=u+vw=u+v的结果，只需要将vv的起点移动到uu的尖端，然后由uu的起点指向vv的尖端

[![](https://i.loli.net/2019/12/27/8JcbfhL96vIaAoR.png)](https://i.loli.net/2019/12/27/8JcbfhL96vIaAoR.png)

这是线性代数中为数不多的允许向量的起点离开原点的情况

为什么这样定义向量加法？

因为我们可以将一个向量看作一段运动，可以发现在上图中，我们先按照uu向量所描述的方式运动，再按照vv向量所描述的方式运动，最后与直接按照ww向量所描述的方式运动是等价的

它也刚好对应了向量所代表的数值上的加法运算：

[31]+[2−2]=[3+21−2]=[5−1][31]+[2−2]=[3+21−2]=[5−1]

### 向量数乘#

对于一个向量

[![](https://i.loli.net/2019/12/27/UQwxI3g2zFslT8r.png)](https://i.loli.net/2019/12/27/UQwxI3g2zFslT8r.png)

我们将它乘以一个标量22得到：

[![](https://i.loli.net/2019/12/27/Cs9PL4HcDjJrmaQ.png)](https://i.loli.net/2019/12/27/Cs9PL4HcDjJrmaQ.png)

效果就是将长度伸长为原来的两倍

如果我们将它乘以1212呢？

[![](https://i.loli.net/2019/12/27/nFl4IuQOjr2sZiM.png)](https://i.loli.net/2019/12/27/nFl4IuQOjr2sZiM.png)

效果就是先反向，然后长度缩小为原来的1212

实际上自始自终，标量在线性代数中的主要作用就是缩放向量

从数字角度看，每个向量数乘即将每一个分量乘以这个数字

2∗[42]=[2∗42∗2]=[84]2∗[42]=[2∗42∗2]=[84]

## 线性组合#

### 线性组合：#

两个向量通过改变数乘的标量而产生新的向量

我们可以从另外一个角度去理解一个向量的坐标：对于一个向量的放缩

[![](https://i.loli.net/2019/12/27/CEQsDOM1cn65HmS.png)](https://i.loli.net/2019/12/27/CEQsDOM1cn65HmS.png)

对于向量vv来说，我们可以看作是由ii伸长为原来的33倍，jj反向伸长为原来的22倍再相加得到的

[![](https://i.loli.net/2019/12/27/96al7GhYQn3wTgU.png)](https://i.loli.net/2019/12/27/96al7GhYQn3wTgU.png)

此时向量vv的横纵坐标作为一个标量对两个向量进行放缩，放缩后的向量通过加和得到了向量vv

其中ii和jj被称为坐标系的基，或者基向量，它表示它是某个的向量坐标放缩并加和的对象

则二维空间中所有的向量都是由两个基向量线性组合得到的

### 张成的空间#

两个向量线性组合得到的所有向量的集合称为张成的空间

我们发现，所有的向量都可以由基向量组合表示，也就是说如果我们选取了不同的基向量那么将会产生不同的坐标系

比如我们选取了下面的两个向量作为基向量

[![](https://i.loli.net/2019/12/27/xdqhwQVTZnrvJpc.png)](https://i.loli.net/2019/12/27/xdqhwQVTZnrvJpc.png)

那么我们仍然可以通过基向量的线性组合产生二维空间中所有的向量，虽然对于同一组向量来说它们的坐标表示也许不太相同

那么我们称这组新的基向量u,vu,v张成的空间为二维平面

我们考虑一种特殊情况

[![](https://i.loli.net/2019/12/27/H1R3NXjkUPAthrQ.png)](https://i.loli.net/2019/12/27/H1R3NXjkUPAthrQ.png)

两个向量只能组合出与当前向量共线的全部向量，我们称i,ji,j张成的空间为一条直线

对于这种特殊情况，我们概括为：某一个向量的增加对于张成的空间没有添加新的维度，那么我们称这组向量是线性相关的

或者说其中一个向量是由其他向量线性组合得到的，则这组向量线性相关

对应地，如果我们每个向量都对张成的空间增加了新的维度，那么我们称这组向量线性无关

还有更特殊的情况，比如两个向量都是原点，那么张成的空间就是一个点

### 基#

然而注意到在特殊情况中我并没有称两个向量为基向量，因为基向量有严格的定义：

向量空间中的一组基是张成该空间的一个线性无关向量集

## 线性变换#

### 线性变换定义#

变换其实和函数的定义类似，不过变换是输入一个向量，再输出一个向量

对于一个空间的变换其实由很多，比如拉伸，扭曲，旋转等等，但是我们考虑的只有线性变换

那么什么才是线性的变换呢？

1.直线在变换后仍然是直线

2.原点保持固定

我相信你们能够脑补出什么是线性变换，什么不是线性变换，因为这个东西我并没有找到合适的画图工具展现出来……

但是对于一个经典的例子我由必要手绘一下

[![](https://i.loli.net/2019/12/27/eXinxAlOyP8fSRm.png)](https://i.loli.net/2019/12/27/eXinxAlOyP8fSRm.png)

对于这样一个变换，它并不是线性的，因为某些我们没有展示在图中的线发生了扭曲

可以自行脑补一下原图中F−N−RF−N−R这条直线变换之后的形状（草老子画不出来啊）

我们其实可以认为，一个变换如果保持网格线之间平行并且等距，那么这个变换是线性变换

那么我们如何通过数值去描绘一个线性变换？

考虑到基向量的特殊性，我们只需要描述线性变换之后基向量在原空间中的坐标，就可以表示出这个变换的效果

同时线性变换有重要的推论：对于一个向量vv，它在变换前和变换后都是基向量的特定的线性组合得到的

即 我们设d′d′是向量dd经过某个线性变换的向量,那么如果

v=x∗i+y∗jv=x∗i+y∗j

则

v′=x∗i′+y∗j′v′=x∗i′+y∗j′

其中x,yx,y是标量

举个例子，一个向量(2,4)(2,4)，如果经过了某个线性变换，基向量由(1,0)(1,0)和(0,1)(0,1)变为了(2,1)(2,1)和(1,2)(1,2)

那么这个向量在变换后的坐标应该为2∗(2,1)+4∗(1,2)=(8,10)2∗(2,1)+4∗(1,2)=(8,10)

### 线性变换与矩阵#

由上面可以得出，对于任意一个线性变换，只要记录了变换之后的基向量，和原向量，就可以得到变换之后的新向量

如果我们的基向量变为了(2,1)和(1,2)(2,1)和(1,2)，那么对于任意向量[xy][xy]，我们可以通过

[xy]′=x∗[21]+y∗[12][xy]′=x∗[21]+y∗[12]得到变换后的向量

我们通常把基向量(a,c),(b,d)(a,c),(b,d)封装为一个2∗22∗2的矩阵，将变换过程称为矩阵乘法

[a bc d] [xy]=[xy]′[a bc d] [xy]=[xy]′

在这里一个2∗22∗2的矩阵即表示一个线性变换，其中每一列是变换后的一个基向量

我们仔细分解一下矩阵乘法的过程

[a bc d] [xy]=x∗[ac]+y∗[bd]=[x∗a+y∗bx∗c+y∗d][a bc d]
[xy]=x∗[ac]+y∗[bd]=[x∗a+y∗bx∗c+y∗d]

现在也许能更清楚地理解为什么矩阵乘法要这样定义了

试着用矩阵描述一些变换：

把空间逆时针旋转90。90。

意味着：[ 0 −11 0][ 0 −11 0]（这东西怎么这么丑啊qwqqwq）

有一个特殊的概念：如果我们矩阵中的几个向量是线性相关的，会导致 ~~你遭受降维打击~~ 变换之后空间维度降低

### 线性变换复合与矩阵乘法#

有时候我们需要连续描述两个或多个线性变换，但是我们仍然可以追踪基向量的变化来实现对变换的描述

不过我们可能需要借助一些工具来描述，比如矩阵

假设我们要对一个空间进行两次变换：先旋转再剪切

我们先将空间逆时针旋转90。90。得到

[ 0 −11 0][xy][ 0 −11 0][xy]

再剪切（想要知道为什么这个矩阵叫做剪切可以自己模拟一下把基向量变成矩阵的两列）

[1 10 1]([ 0 −11 0][xy])[1 10 1]([ 0 −11 0][xy])

那么它将等价于

([1 10 1][ 0 −11 0])[xy]=[ 1 −11 0][xy]([1 10 1][ 0 −11 0])[xy]=[ 1 −11 0][xy]

我们称左边的矩阵为等价矩阵

考虑在几何中我们两个变化的描述应该为，基向量先变为了(0,1),(−1,0)(0,1),(−1,0)，又在新的空间中变为了(1,0),(1,1)(1,0),(1,1)，那么以左边两个矩阵的乘法作为两个变换连续的效果是很合理的（矩阵中描述变换从右向左描述）

如何计算两个矩阵相乘？

还记得我们矩阵的含义吗，每一列代表了一个向量

也就是说对于

[e fg h][a bc d][e fg h][a bc d]，我们可以看作右边的矩阵的每一列代表的向量做左边的变换

[e fg h][a bc d]=[e fg h][ac]+[e fg h][bd]=[ae+bg af+bhce+dg cf+dh][e fg h][a
bc d]=[e fg h][ac]+[e fg h][bd]=[ae+bg af+bhce+dg cf+dh]

中间应该还有一步向量乘变换，懒得展开了

当然我们应该可以通过这个过程发现矩阵乘法并不满足交换律

但是它为什么满足结合律呢？

考虑矩阵变换是从右向左描述的，所以……矩阵乘法中加不加括号在几何意义上根本没有任何变化

高维的情况应该可以自己推出来，但是实在是难以表述&作出图，所以就不在这里写了

## 行列式#

在线性变换中，也许我们会想要知道一个问题：在经过了某个线性变换之后，原空间受到了多少拉伸或者挤压？

或者转化成一个在二维平面中等价的问题：一个给定区域的面积大小的变化

### 行列式定义#

一个线性变换对“体积”所造成的影响。

当然由于是在二维平面中的线性变换，所以我们在研究这个问题的时候可以只研究一个特殊部分：两个基向量围成的四边形的面积的变化比例

比如说：一个2∗22∗2矩阵的行列式为33，那么说明i,ji,j两个基向量四边形的面积变为原来的三倍

特殊地：有些矩阵的行列式为00，例如：det([1 30 0])=0det([1 30 0])=0

这表示在经过这个线性变换之后空间将降维

另外还有det([0 11 0])=−1det([0 11 0])=−1

虽然在经过[0 11 0][0 11
0]这个变换之后i,ji,j两个基向量之间的四边形面积仍然是11，但是我们会发现，ii向量变到了jj向量的左边，两个向量的相对位置交换了，空间的定向发生了改变，所以得到的行列式值为负

类比可以推出：在三维空间中，一个线性无关方程组的行列式的值代表的是三个向量确定的平行六面体的体积

如果在三维情况下行列式的值为负呢？

这里有一个用来描述三维空间空间定向的方法，叫做 “右手定则”

在一个三维空间中，我们假设基向量为i,j,ki,j,k，分别对应x,y,zx,y,z轴

一般情况下，我们右手食指指向ii，中指指向jj，大拇指指向kk

如果在某个线性变换之后，你做到这一步需要变成左手，那么说明这个三维空间的定向发生了改变，此时行列式的值应该为负

对于行列式的计算我打算单独拿出来讲，因为本篇文章偏入门，这里只介绍行列式的定义和概念

不过由于后面的需要，我需要指出对于2∗22∗2的矩阵[a bc d][a bc d]，它的行列式为ad−bcad−bc

如果你真的理解了行列式的具体含义，你应该可以很轻易的理解下面这个等式

设MiMi为某个线性变换矩阵

det(M1M2)=det(M1)det(M2)det(M1M2)=det(M1)det(M2)

## 线性方程组#

在某些情况下，方程组会具有一个非常特殊的形式：

在每个方程中，未知量只具有常系数，未知量之间只进行加和操作

⎧⎩⎨2x+5y+3z=−34x+0y+8z=01x+3y+0z=2{2x+5y+3z=−34x+0y+8z=01x+3y+0z=2

整理这种方程组通常是将所有未知量放在侧坐，将相同的未知量放在同一列对齐（有可能需要补00完成这一步），其他常量放在等式右侧

我们称这种方程组为线性方程组

其实我们会发现这种方程组对应着一个矩阵的形式

⎡⎣⎢2 5 34 0 81 3 0⎤⎦⎥⎡⎣⎢xyz⎤⎦⎥=⎡⎣⎢−302⎤⎦⎥[2 5 34 0 81 3 0][xyz]=[−302]

我们称左侧的系数矩阵为AA,包含未知量的矩阵为xx，右侧的结果矩阵为vv

则可以简写为Ax=vAx=v，结合前面的知识，我们已经可以发现这其实是一个线性变换了

那么这个求解线性方程组就具备了它的几何意义：对于一个线性变换后空间中的向量，找到在原空间的对应向量

那么对于这个问题我们需要稍微分类讨论一下了，因为我们面临两种情况：det(A)=0det(A)=0和det(A)≠0det(A)≠0

先来考虑似乎较为简单的det(A)≠0det(A)≠0

那么说明原空间经过AA之后并没有降低维度，原空间中应该只有一个向量与vv对应（这个不用解释吧应该？）

但是我们只有变换之后的向量，如果要追寻原本的向量，我们应该将vv做一个AA的逆变换，记作A−1A−1

所谓逆的含义应该在学乘法逆元的时候都有所了解了，大概可以总结为A−1∗A=EA−1∗A=E,其中EE为恒等变换

对于nn维空间，EE是一个对角全部为11，其它区域全部为00的n∗nn∗n的矩阵

所以可以推出：

A−1Ax=A−1vA−1Ax=A−1v

x=A−1vx=A−1v

但是特殊的det(A)=0det(A)=0怎么办？

经过AA之后，空间会直接降维，此时AA是不存在逆矩阵的，因为没有一种变换能使空间维度提升

但是解仍然可能存在，如果你的vv恰好处于降完维之后的空间之中

至于解是什么，就不打算在本篇说明了（雾）

### 秩#

经过线性变换之后空间的维度，我们称为秩

比如一个平面，我们将他旋转，那么旋转之后它的秩为22

但是如果经历了一个[1 30 0][1 30 0],它的秩为11

可以发现对于每一个 ~~降智~~ 降秩的变换，矩阵的行列式值都为00

### 列空间#

对于一个线性变换AA来说，所有可能的向量AvAv的集合，我们称为AA的列空间

当然这个名字的来源很好理解……因为向量AvAv的集合其实就是构成矩阵的每一列的向量的所有线性组合成的向量

所谓列空间，其实就是列向量张成的空间，所以秩更准确的定义应该是列空间的维数

当秩达到最大时，与矩阵的列数相等，称之为满秩

### 零空间#

值得注意：00向量必定在列空间中，因为线性变换必须保持原点不动

但是00向量并不一定只是原点，举个例子，在某个二维变换AA中，若det(A)=0det(A)=0，那么某条直线上的所有向量将会全部压缩到原点

在某个线性变换AA中，所有变换后落在原点的向量的集合，称为零空间（或者核)

所以对于Ax=vAx=v中，如果vv是零向量，那么所有xx的解将是整个零空间

## 非方阵#

目前为止，我们讨论的变换方阵都是n∗nn∗n的方阵，那么对于非方阵我们应该怎样理解？

例如一个3∗23∗2的矩阵⎡⎣⎢1 34 12 3⎤⎦⎥[1 34 12 3]

它说明我们在二维空间中的两个基向量i,ji,j在经过某个线性变换之后对应到了某个三维空间中的二维平面

注意它对应到的是某个三维空间中的二维平面，而不是某个三维空间，没有一种变换能让空间升维

或者令一种1∗21∗2的矩阵[1 2][1 2]

意味着某个二维空间经过线性变换之后降低到了一维，但是它仍然有两个基向量

这对点积有着重要的意义

## 点积#

### 点积定义#

我们来回忆一下高中数学中的点积：

代数意义：对于两个行数相同的矩阵⎡⎣⎢abc⎤⎦⎥⋅⎡⎣⎢efg⎤⎦⎥=ae+bf+cg[abc]·[efg]=ae+bf+cg，当然不一定是三维的

几何意义：u⋅vu·v应该是vv在uu上的投影的长度乘以uu的模长

[![](https://i.loli.net/2019/12/27/DzCdGiNo2Z6STK9.png)](https://i.loli.net/2019/12/27/DzCdGiNo2Z6STK9.png)

即u⋅vu·v=（vv的投影长度）*（uu的模长）

如果vv的投影方向与uu相反那么点积的值应该为负

现在你有没有一个问题：这两种解释有什么关系？？？？？？

### 对偶性#

根据线性变换的规定，如果我们有一个高维对一维的线性变换，那么对于原空间中等距分布在一条直线上的一些点，应用完线性变换之后在数轴上仍然等距

然而对于高维对一维的线性变换，我们所有的基向量都会落在一个数轴上，也就是说会产生一个1∗n1∗n的变换矩阵，例如[2 1][2 1]

考虑它对原空间某个向量[xy][xy]的影响2∗x+1∗y2∗x+1∗y

等价于矩阵乘法中[2 1][xy][2 1][xy]

然而我们发现这个过程貌似和点积是运算非常相似！

这个1∗n1∗n的矩阵不就是一个躺倒的向量吗？

但是线性代数中显然没有躺倒或者直立这种操作……但是这恰好说明一个高维对一维的线性变换和一个高维向量之间存在在某种对应关系

以二维来举例子

我们在二维空间中放置一条数轴，其基向量为uu

[![](https://i.loli.net/2019/12/27/uLCdbysUANij1r7.png)](https://i.loli.net/2019/12/27/uLCdbysUANij1r7.png)

考虑某一种线性变换：对于任意向量vv，求出这条向量在数轴上的投影

那么我们在描述变换的时候应该考虑的就是，变换后i,ji,j的位置

这里有就非常有趣的东西了！

[![](https://i.loli.net/2019/12/27/2lnGK6E4uorZbBh.png)](https://i.loli.net/2019/12/27/2lnGK6E4uorZbBh.png)

我们作kk是角GCDGCD的角平分线，会发现GC=HCGC=HC，即ii向数轴的投影就是uu向xx轴的投影，而uu向xx轴的投影就是uu的横坐标！

同理jj向数轴的投影就是uu的纵坐标

所以这个线性变换完全可以表示为[ux uy][ux uy]

而对于一个数轴非基向量uu，我们可以看作基向量的线性变换再乘以uu的模长

这就是为什么对于一个vv在uu上的投影的长度乘以uu的模长这样的操作，我们用矩阵来描述就是

[ux uy][vxvy][ux uy][vxvy]

而它恰恰与[uxuy][vxvy][uxuy][vxvy]在数值上是一致的！

神奇的对偶性

## 叉积#

### 叉积定义#

两个向量的叉积，即两个向量围成的平行四边形的面积（虽然两个向量是两条线段，但是你们都懂我意思对吧~）

对于v×uv×u，如果vv在uu右侧，那么结果为正，否则结果为负

所以说顺序对叉积的结果是有影响的

v×u=−u×vv×u=−u×v

也许你会发现这和行列式有一点相似？这是行列式计算的是基向量围成的面积

那么我会告诉你，v×u=det([vx uxvy uy])v×u=det([vx uxvy uy])

但是严格地说它并不是叉积……

叉积严格的定义是由两个三维向量生成一个新的三维向量

其长度为面积的值，方向垂直于两个向量所在的平面

不过是向哪边垂直呢？我们需要右手定则

右手食指指向vv，中指指向uu，大拇指就是叉积的方向

我们是怎么求一个叉积的？

一般计算的时候 ~~也许~~ 会有个老师告诉你：

计算两个向量⎡⎣⎢v1v2v3⎤⎦⎥×⎡⎣⎢u1u2u3⎤⎦⎥=det(⎡⎣⎢i v1 u1j v2 u2k v3
u3⎤⎦⎥)[v1v2v3]×[u1u2u3]=det([i v1 u1j v2 u2k v3 u3])

（可能在某些书中或者博客中矩阵是横过来的，不过结果是一样的）

右边矩阵的第一列居然是一组基向量？

如果你头铁继续往下算，会得到i(v2u3−v3u2)+j(v1u3−v3u1)+k(v1u2−v2u1)i(v2u3−v3u2)+j(v1u3−v3u1)+k(v1u2−v2u1)

虽然你不知道为什么向量能够放到矩阵中去算行列式，也不知道为什么这样算出来的结果是叉积，但是也许你有很多种方法验证发现得到的结果的确是vv和uu的叉积

我们需要一个解释

### 对偶性#

这里我们需要用到对偶性

回忆一下对偶性：

任何一个高维空间向一维空间的线性变换，都能在高维空间中找到一个向量唯一对应，使得某个向量应用这个线性变换等价于于这个高维向量做点积

数值上说是因为这个任何一个向量与这个线性变换做矩阵乘法和对应的高维向量做矩阵乘法结果都是一样的

考虑一下如果我没有告诉你什么是真正的叉积，并且你预先也没有了解，然后在看完二维空间中叉积的计算之后，会怎样考虑三维空间的叉积？

那么大概率会认为是三个向量的行列式

然而事实上叉积是接收两个向量并输出一个向量

那么我们假设有一个函数f(⎡⎣⎢xyz⎤⎦⎥)=det(⎡⎣⎢x v1 u1y v2 u2z v3 u3⎤⎦⎥)f([xyz])=det([x v1 u1y
v2 u2z v3 u3])

这个函数是线性的（线性定义：f(a+b)=f(a)+f(b),f(ka)=kf(a)f(a+b)=f(a)+f(b),f(ka)=kf(a)其中kk是标量）

这说明它对应着一个三维对一维的线性变换

那么ff函数其实可以写成

[p1 p2 p3]⎡⎣⎢xyz⎤⎦⎥=det(⎡⎣⎢x v1 u1y v2 u2z v3 u3⎤⎦⎥)[p1 p2 p3][xyz]=det([x v1
u1y v2 u2z v3 u3])

根据对偶性，它等价于

⎡⎣⎢p1p2p3⎤⎦⎥⋅⎡⎣⎢xyz⎤⎦⎥=det(⎡⎣⎢x v1 u1y v2 u2z v3 u3⎤⎦⎥)[p1p2p3]·[xyz]=det([x
v1 u1y v2 u2z v3 u3])

考虑这个式子的意义：一个向量pp与一个未知向量xx的点积等于x,vx,v和uu的行列式

我们已经知道在三维空间中，三个线性无关向量的行列式是一个平行六面形，那我们考虑点积的几何含义：pp在xx上的投影乘以xx的模长（交换x,px,p没有关系）

平行六面体的体积求法应该是底面积乘以第三个向量在垂直于底面上的投影

那么如果我们把pp看作第三个向量，那么xx就应该满足：长度等于平行六面体的底面积，且垂直于底面

在上面的等式中底面的边是v,uv,u，这个xx完美符合v,uv,u叉积的定义！

所以说v×u=det(⎡⎣⎢i v1 u1j v2 u2k v3 u3⎤⎦⎥)v×u=det([i v1 u1j v2 u2k v3 u3])

解出以后的i(v2u3−v3u2)+j(v1u3−v3u1)+k(v1u2−v2u1)i(v2u3−v3u2)+j(v1u3−v3u1)+k(v1u2−v2u1)作为一个向量，就是⎡⎣⎢xyz⎤⎦⎥[xyz]

upd:upd:叉积似乎还有更高维的定义，不太了解

## 基变换#

### 不同基向量变换#

在前面我们提到过，对于一个向量的坐标，我们可以解读为对于基向量的放缩

例如某个向量坐标为(3,2)(3,2)，我们可以理解为将ii伸长33倍，再将jj伸长22倍，然后通过相加得到向量[32][32]

通常意义上我们的i,ji,j分别选取(1,0),(0,1)(1,0),(0,1)

但是如果选取不同的基向量呢？

比如有一个帅比叫动动，它选取了(2,1),(−1,1)(2,1),(−1,1)两个向量作为基向量，称之为t1,t2t1,t2

那么他对于[32][32]应该是[5313][5313]

因为在他看来，这个向量是由53t1+13t253t1+13t2得到的

但是这个有一个奇特的地方

在动动的视角中，他认为的基向量是(1,0),(0,1)(1,0),(0,1)，所谓的(2,1),(−1,1)(2,1),(−1,1)只是以我们的视角来命名的

所以实际上我们的语言是不同的，对于同一向量，我们叫它[32][32]，而动动叫它[5313][5313]

问题就来了

由于动动是帅比，你非常想和他做朋友，但是你们说着不同的语言，所以我们要学会不同语言之间的转化（不同坐标系之间的转化）

具体地说，对于动动说出的一个向量[−12][−12],在我们的语言中它应该如何表示？

[![](https://i.loli.net/2019/12/29/wCEJFGidfZmX8RM.png)](https://i.loli.net/2019/12/29/wCEJFGidfZmX8RM.png)

在我们的语言中，t1=[21],t2=[−11]t1=[21],t2=[−11]，所以向量v=−1[21]+2[−11]=[−41]v=−1[21]+2[−11]=[−41]

所以我们所说的[−41][−41]就是动动所说的[−12][−12]

结合这个形式，很容易发现这其实是一个线性变换的过程

当然，这只是我们读懂了动动的语言，但是如果要做♂朋♂友，那么显然动动也要读懂我们的语言

例如我们所说的[32][32]，动动如何知道在它的语言中是[5313][5313]表示

观察刚才我们理解动动语言的过程，实际上动动理解我们的语言应该是一个逆过程

在刚刚的线性变换中，我们把我们的坐标系变为了动动的坐标系，应用了变换矩阵[2 −11 1][2 −11 1]

那么让动动的坐标系变为我们的坐标系，应该应用这个矩阵的逆矩阵[2 −11 1]−1[2 −11 1]−1

它代表我们所描述的变换逆向进行

可以算出[2 −11 1]−1=[13 13−13 23][2 −11 1]−1=[13 13−13 23]

动动想要知道我们说的坐标在它的语言中如何表示，应该[13 13−13 23][32]=[5313][13 13−13 23][32]=[5313]

其实如果换一个角度：动动是正确的坐标系，我们才是变换过的坐标系，那么这个过程很好理解

### 不同基线性变换#

但是实际上动动和我们之间的语言差异并不只在某一向量上

比如我们描述某一线性变换：逆时针旋转90。90。，我们用[0 1−1 0][0 1−1 0]

但是[01][01]和[−10][−10]是我们语言中变换后的基向量，并不是动动的

如果我们想对动动表达逆时针旋转90。90。，我们该怎么办？

我们可以先把动动的基向量转化为我们的语言，然后应用线性变换再转化回去！

比如我们想知道动动语言中的某个向量vv旋转后在动动语言中如何描述

设AA为基变换矩阵，MM为旋转矩阵，则整个过程可以表示为 A−1MAvA−1MAv，注意矩阵从右向左变换

其中A−1MAA−1MA就是旋转在动动语言中的矩阵形式

## 特征向量与特征值#

### 特征向量与特征值定义#

考虑某个线性变换[3 01 2][3 01 2]

在这个线性变换下，大部分向量会离开它张成的空间

[![](https://i.loli.net/2019/12/29/8moRhgNknzdZlVi.png)](https://i.loli.net/2019/12/29/8moRhgNknzdZlVi.png)

但是有些向量很特殊，它会留在原本张成的空间中

[![](https://i.loli.net/2019/12/29/d9eTBvxngQMOzla.png)](https://i.loli.net/2019/12/29/d9eTBvxngQMOzla.png)

这个线性变换对它来说只不过是拉伸或者压缩，作用同一个标量

如[1−1][1−1]，在经过[3 01 2][3 01 2]只是伸长为22倍

同时说明对于原来[1−1][1−1]张成空间内的任意向量，都只是伸长为22倍

对于这类变换之后没有离开张成空间的向量，我们称为变换的特征向量，每一个特征向量都有一个所属的值，称为特征值，即衡量压缩或拉伸比例的值

你们肯定能猜到特征值可以为负或者为零

那么它有什么作用呢？

事实上以前我们研究线性变换过于依赖坐标轴，但是线性变换本身应该和坐标轴是无关的，通过特征向量和特征值也许可以更深刻的理解线性变换

### 特征值的计算思想#

对于一个线性变化AA，设vv是它的某个特征向量，其特征值为λλ

那么Av=λvAv=λv

但是我们根本解不了这么个东西……因为等式左边是一个矩阵乘法而右边是向量数乘

所以我们应该将λλ替换为某个矩阵，其效果为将任意向量乘以λλ

由于矩阵的每一列代表了变换后的基向量，所以我们只要让主对角线全部为λλ，其它地方全部为00

通常也写作λEλE，其中EE为恒等变换

我们变形一下式子得到(A−λE)v=0(A−λE)v=0

如果vv本身是零向量那么这个式子恒成立，但是我们一般不需要解出一个零向量作为特征向量

根据前面的知识，我们知道一个非零向量经过一个线性变换变换为了一个零向量，那么这个线性变换一定降维，或者说行列式的值为00

即det(A−λE)=0det(A−λE)=0

但是有些线性变换其实并不存在特征向量，比如旋转

在这种线性变换中，我们会解出一个虚数作为它的特征值

### 特征值优化矩阵乘法#

考虑一个特殊情况：所有的基向量都是特征向量：

那么我们可以发现，这个线性变换对应的矩阵是一个对角矩阵，即只有主对角线上有值，其它地方都是00

它有什么良好的性质呢？

性质就是对于一个对角矩阵，在自乘的时候复杂度为O(n)O(n)而非n3n3

这对我们有一个启发：如果某个线性变换，它的特征向量很多，多到能够与维数同样多

那么我们可以变换坐标系，使这些特征向量作为我们的基向量，然后进行快速的矩阵乘法，再将坐标系变换会原本的状态

我们就可以O(n3+nlogk)O(n3+nlogk)实现矩阵快速幂

## 抽象向量空间#

回到原本的问题：向量是什么？

回顾行列式和特征向量的定义：

一个代表某个线性变换对空间的压缩或拉伸程度

一个代表某个线性变换中没有离开张成空间的向量

好像和一个箭头或者一列数字都没有直接的联系

为了解释向量到底是什么，我们引入一个看似与向量毫无关联的东西：函数

假设我们现在有了函数f(x)f(x)和g(x)g(x)，考虑它们的性质

我们可以把两个函数相加，得到新函数(f+g)(x)=f(x)+g(x)(f+g)(x)=f(x)+g(x)，和向量加法非常类似

那么对于函数与实数相乘，得到新函数(λf)(x)=λf(x)(λf)(x)=λf(x)，也有着和向量数乘极为类似的解释

其实我们对向量能够进行的操作只有相加和数乘，那么同样具备这些操作的函数理论上来说就可以直接套用所有向量相关的推论

在这里我们要重新描述一下线性的严格定义

可加性：f(x+y)=f(x)+f(y)f(x+y)=f(x)+f(y)

成比例f(λx)=λf(x)f(λx)=λf(x)

如果一个变换在应用之后仍然对于原x,yx,y满足这些性质，那么称这个变换是线性变换

根据这个定义我们可以发现一个也许并没有听说过的定理：求导是线性运算

为了类比求导与线性变换之间的关系，我们尝试用矩阵描述求导

假设我们有一个多维空间，其空间组成为：全体多项式

首先我们要赋予空间坐标的含义，即选取基向量，或者说基函数

很自然我们应该选取xx的不用次幂作为基函数，因为多项式次数可以任意高，所以我们的基函数几何应该是无穷大的

对于某个多项式：2x2+3x+12x2+3x+1，我们可以表示为⎡⎣⎢⎢⎢⎢⎢⎢⎢1320⋮⎤⎦⎥⎥⎥⎥⎥⎥⎥[1320⋮]

在这个向量之中，求导可以用一个无限阶的矩阵来描述

ddx=⎡⎣⎢⎢⎢⎢⎢0 1 0 0 ⋯0 0 2 0 ⋯0 0 0 3 ⋯⋮ ⋮ ⋮ ⋱⎤⎦⎥⎥⎥⎥⎥ddx=[0 1 0 0 ⋯0 0 2 0 ⋯0 0
0 3 ⋯⋮ ⋮ ⋮ ⋱]

然后我们对某一个多项式求导ddx(5x2+4x+5)=3x2+10x+4ddx(5x2+4x+5)=3x2+10x+4，用矩阵描述为

⎡⎣⎢⎢⎢⎢⎢0 1 0 0 ⋯0 0 2 0 ⋯0 0 0 3 ⋯⋮ ⋮ ⋮
⋱⎤⎦⎥⎥⎥⎥⎥⎡⎣⎢⎢⎢⎢545⋮⎤⎦⎥⎥⎥⎥=⎡⎣⎢⎢⎢⎢4103⋮⎤⎦⎥⎥⎥⎥[0 1 0 0 ⋯0 0 2 0 ⋯0 0 0 3 ⋯⋮ ⋮ ⋮
⋱][545⋮]=[4103⋮]

对求导矩阵的构造，只要将基函数每一项进行求导，然后按列排布

为什么我们要类比求导和矩阵的关系？

为了说明：只要我们处理的对象的集合满足相加和数乘原则，都可以称之为向量，对应的，向量的所有推论在这些对象中都适用

我们可以大概概括为：向量是满足了相加和数乘原则的事物的集合

## 结尾#

终于肝完了线代入门

由于技术原因本文难以加入大量形象的图片，还有不了解的可以观看[原视频](https://www.bilibili.com/video/av6731067?p=4)

再次大力膜拜3B1B3B1B

分类: [笔记](https://www.cnblogs.com/knife-rose/category/2280713.html)

[](https://github.com/knife-rose "Github")

Sponsor

  * PayPal
  * AliPay
  * WeChat

[好文要顶](javascript:void\(0\);) [关注我](javascript:void\(0\);)
[收藏该文](javascript:void\(0\);)
[![](https://common.cnblogs.com/images/icon_weibo_24.png)](javascript:void\(0\);
"分享至新浪微博")
[![](https://common.cnblogs.com/images/wechat.png)](javascript:void\(0\);
"分享至微信")

[![](https://pic.cnblogs.com/face/1736831/20210616212229.png)](https://home.cnblogs.com/u/knife-
rose/)

[lovelyred](https://home.cnblogs.com/u/knife-rose/)  
[粉丝 - 66](https://home.cnblogs.com/u/knife-rose/followers/) [关注 -
31](https://home.cnblogs.com/u/knife-rose/followees/)  

[+加关注](javascript:void\(0\);)

10

0

[« ](https://www.cnblogs.com/knife-rose/p/12106485.html) 上一篇：
[最小割的数学形式](https://www.cnblogs.com/knife-rose/p/12106485.html "发布于 2019-12-27
11:40")  
[» ](https://www.cnblogs.com/knife-rose/p/12120373.html) 下一篇：
[微积分入门](https://www.cnblogs.com/knife-rose/p/12120373.html "发布于 2019-12-31
12:37")

posted @ 2019-12-27 17:16 [lovelyred](https://www.cnblogs.com/knife-rose/)
阅读(2250) 评论(9) [编辑](https://i.cnblogs.com/EditPosts.aspx?postid=12107204)
[收藏](javascript:void\(0\)) [举报](javascript:void\(0\))

[刷新评论](javascript:void\(0\);)刷新页面返回顶部

登录后才能查看或发表评论，立即 [登录](javascript:void\(0\);) 或者 [逛逛](https://www.cnblogs.com/)
博客园首页

[【推荐】阿里云开发者社区：AI入门必修，9分钟搭建文生图应用，提交创作心得赢好礼](https://click.aliyun.com/m/1000377296/)  
[【推荐】快速上手阿里云RDS
MySQL，3个月免费资源，5分钟完成体验必得胶囊雨伞](https://click.aliyun.com/m/1000377221/)  
[【推荐】行行AI人才直播第14期：《土豆利用GPT成功融资两次的提示词和故事》](https://www.cnblogs.com/cmt/p/17588697.html)  
[【推荐】阿里云-云服务器省钱攻略 ：五种权益，限时发放，不容错过](https://click.aliyun.com/m/1000376076/)  

**编辑推荐：**  
· [小细节，大问题。分享一次代码优化的过程](https://www.cnblogs.com/eryuan/p/17593372.html)  
· [写给软件编程新手的建议](https://www.cnblogs.com/lzhdim/p/17590227.html)  
· [golang技术降本增效的手段](https://www.cnblogs.com/JulianHuang/p/17587159.html)  
· [你不知道的 HTTP Referer](https://www.cnblogs.com/songyao666/p/17584275.html)  
· [记录一次线上服务 CPU 飙高问题](https://www.cnblogs.com/teach/p/17582912.html)  

**阅读排行：**  
· [简单了解一下国产操作系统](https://www.cnblogs.com/morvenhuang/p/17592832.html)  
· [是时候丢掉BeanUtils了](https://www.cnblogs.com/jtea/p/17592696.html)  
· [跟进 .NET 8 Blazor 之 ReuseTabs 支持 Query
属性绑定](https://www.cnblogs.com/ElderJames/p/ant-blazor-reusetabs-supports-
supply-parameter-form-query.html)  
· [小细节，大问题。分享一次代码优化的过程](https://www.cnblogs.com/eryuan/p/17593372.html)  
·
[NativeBuferring，一种零分配的数据类型[上篇]](https://www.cnblogs.com/artech/p/17586781.html)  

### 公告

昵称： [ lovelyred ](https://home.cnblogs.com/u/knife-rose/)  
园龄： [ 4年 ](https://home.cnblogs.com/u/knife-rose/ "入园时间：2019-07-08")  
粉丝： [ 66 ](https://home.cnblogs.com/u/knife-rose/followers/)  
关注： [ 31 ](https://home.cnblogs.com/u/knife-rose/followees/)

[+加关注](javascript:void\(0\))

|  [<](javascript:void\(0\);) | 2023年8月 |  [>](javascript:void\(0\);)  
---|---|---  
日 | 一 | 二 | 三 | 四 | 五 | 六  
30 | 31 |  1  |  2  |  3  |  4  |  5  
6  |  7  |  8  |  9  |  10  |  11  |  12  
13  |  14  |  15  |  16  |  17  |  18  |  19  
20  |  21  |  22  |  23  |  24  |  25  |  26  
27  |  28  |  29  |  30  |  31  |  1  |  2  
3  |  4  |  5  |  6  |  7  |  8  |  9  
  
###  [随笔分类](https://www.cnblogs.com/knife-rose/post-categories)

  * [ATC(16)](https://www.cnblogs.com/knife-rose/category/2280703.html)
  * [CF(12)](https://www.cnblogs.com/knife-rose/category/2280702.html)
  * [比赛(10)](https://www.cnblogs.com/knife-rose/category/2280704.html)
  * [笔记(9)](https://www.cnblogs.com/knife-rose/category/2280713.html)
  * [算法(20)](https://www.cnblogs.com/knife-rose/category/2280707.html)

###  随笔档案

  * [2023年2月(2)](https://www.cnblogs.com/knife-rose/archive/2023/02.html)
  * [2022年5月(9)](https://www.cnblogs.com/knife-rose/archive/2022/05.html)
  * [2022年4月(9)](https://www.cnblogs.com/knife-rose/archive/2022/04.html)
  * [2022年3月(1)](https://www.cnblogs.com/knife-rose/archive/2022/03.html)
  * [2022年2月(3)](https://www.cnblogs.com/knife-rose/archive/2022/02.html)
  * [2021年12月(8)](https://www.cnblogs.com/knife-rose/archive/2021/12.html)
  * [2021年11月(5)](https://www.cnblogs.com/knife-rose/archive/2021/11.html)
  * [2021年10月(6)](https://www.cnblogs.com/knife-rose/archive/2021/10.html)
  * [2021年9月(8)](https://www.cnblogs.com/knife-rose/archive/2021/09.html)
  * [2021年8月(6)](https://www.cnblogs.com/knife-rose/archive/2021/08.html)
  * [2021年7月(3)](https://www.cnblogs.com/knife-rose/archive/2021/07.html)
  * [2021年6月(1)](https://www.cnblogs.com/knife-rose/archive/2021/06.html)
  * [2019年12月(6)](https://www.cnblogs.com/knife-rose/archive/2019/12.html)
  * [2019年7月(2)](https://www.cnblogs.com/knife-rose/archive/2019/07.html)
  * [更多](javascript:void\(0\))

###  [ 阅读排行榜 ](https://www.cnblogs.com/knife-rose/most-viewed)

  * [ 1\. 微积分入门(4637) ](https://www.cnblogs.com/knife-rose/p/12120373.html)
  * [ 2\. 线性代数入门(2250) ](https://www.cnblogs.com/knife-rose/p/12107204.html)
  * [ 3\. 「组合数学」一：什么是组合数学(1223) ](https://www.cnblogs.com/knife-rose/p/15253307.html)
  * [ 4\. 「具体数学」二：和式 (972) ](https://www.cnblogs.com/knife-rose/p/15177218.html)
  * [ 5\. 快速傅立叶变换（FFT）(900) ](https://www.cnblogs.com/knife-rose/p/12035605.html)

###  [评论排行榜](https://www.cnblogs.com/knife-rose/most-commented)

  * [ 1\. 快速傅立叶变换（FFT）(12) ](https://www.cnblogs.com/knife-rose/p/12035605.html)
  * [ 2\. 线性代数入门(9) ](https://www.cnblogs.com/knife-rose/p/12107204.html)
  * [ 3\. ABC217(3) ](https://www.cnblogs.com/knife-rose/p/15746153.html)
  * [ 4\. ABC127(3) ](https://www.cnblogs.com/knife-rose/p/15694982.html)
  * [ 5\. 生成函数(2) ](https://www.cnblogs.com/knife-rose/p/15345071.html)

###  [推荐排行榜](https://www.cnblogs.com/knife-rose/most-liked)

  * [ 1\. 微积分入门(14) ](https://www.cnblogs.com/knife-rose/p/12120373.html)
  * [ 2\. 线性代数入门(10) ](https://www.cnblogs.com/knife-rose/p/12107204.html)
  * [ 3\. 万能的进制哈希(4) ](https://www.cnblogs.com/knife-rose/p/11230936.html)
  * [ 4\. 兔队线段树(1) ](https://www.cnblogs.com/knife-rose/p/15203181.html)
  * [ 5\. 快速傅立叶变换（FFT）(1) ](https://www.cnblogs.com/knife-rose/p/12035605.html)

Copyright © 2023 lovelyred  
Powered by .NET 7.0 on Kubernetes & Theme [Silence
v2.0.2](https://github.com/esofar/cnblogs-theme-silence)

[ ](https://github.com/knife-rose "Fork me on GitHub")

CONTENTS

✕

  * __1. 前言
  * __2. 向量
  * __2.1. 向量的定义
  * __2.2. 向量加法
  * __2.3. 向量数乘
  * __3. 线性组合
  * __3.1. 线性组合：
  * __3.2. 张成的空间
  * __3.3. 基
  * __4. 线性变换
  * __4.1. 线性变换定义
  * __4.2. 线性变换与矩阵
  * __4.3. 线性变换复合与矩阵乘法
  * __5. 行列式
  * __5.1. 行列式定义
  * __6. 线性方程组
  * __6.1. 秩
  * __6.2. 列空间
  * __6.3. 零空间
  * __7. 非方阵
  * __8. 点积
  * __8.1. 点积定义
  * __8.2. 对偶性
  * __9. 叉积
  * __9.1. 叉积定义
  * __9.2. 对偶性
  * __10. 基变换
  * __10.1. 不同基向量变换
  * __10.2. 不同基线性变换
  * __11. 特征向量与特征值
  * __11.1. 特征向量与特征值定义
  * __11.2. 特征值的计算思想
  * __11.3. 特征值优化矩阵乘法
  * __12. 抽象向量空间
  * __13. 结尾

![](data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==)

[]()[]()

