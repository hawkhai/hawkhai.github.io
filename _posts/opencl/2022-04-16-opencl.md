---
layout: post
title: "编程与调试 C++ -- OpenCL & CUDA 初探"
author:
location: "珠海"
categories: ["编程与调试"]
tags: ["编程", "C/C++", "OpenCL"]
toc: true
toclistyle:
comments:
visibility:
mathjax:
mermaid:
glslcanvas:
codeprint:
cluster: "OpenCL"
---

**OpenCL 是一个小而美的东西，比 OpenGL 要简单很多，妙不可言。(￣▽￣)"**
OpenGL 需要图形学的知识储备，OpenCL 不太需要。

并行计算行情。
1. CPU
    * 首先是指令集优化：SIMD (SSE, AVX, NEON)
    * 然后多线程跑：
        * OpenMP 标准
        * intel 搞的 TBB, oneTBB 等。
2. GPU
    * NVIDIA 搞的 CUDA
    * [OpenCL {% include relref_khronos.html %}](https://www.khronos.org/opencl/) 标准
        * Unlike 'GPU-only' APIs, such as Vulkan, OpenCL enables use of a diverse range of accelerators including multi-core CPUs, GPUs, DSPs, FPGAs and dedicated hardware such as inferencing engines.
    * DirectX 搞的 DirectCompute
    * 微软尝试从 C++ 语言级别搞的 C++ AMP
3. 机器学习多为 CUDA 而 挖矿程序多为 CUDA 和 OpenCL。


## CL_TARGET_OPENCL_VERSION

```cpp
/* Detect which version to target */
#if !defined(CL_TARGET_OPENCL_VERSION)
#pragma message("cl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 300 (OpenCL 3.0)")
#define CL_TARGET_OPENCL_VERSION 300
#endif

/* cl_device_type - bitfield */
#define CL_DEVICE_TYPE_DEFAULT                      (1 << 0)
#define CL_DEVICE_TYPE_CPU                          (1 << 1)
#define CL_DEVICE_TYPE_GPU                          (1 << 2)
#define CL_DEVICE_TYPE_ACCELERATOR                  (1 << 3)
#ifdef CL_VERSION_1_2
#define CL_DEVICE_TYPE_CUSTOM                       (1 << 4)
#endif
#define CL_DEVICE_TYPE_ALL                          0xFFFFFFFF
```

* OpenCL 2.0 异构计算 [第三版] （Heterogeneous Computing with OpenCL 2.0）
    * <https://www.bookstack.cn/read/Heterogeneous-Computing-with-OpenCL-2.0/content-chapter2-2.2-chinese.md>
* OPENCL：并行世界的桥梁
    * <https://www.mql5.com/zh/articles/405>
* OPENCL：从朴素到更具深度的编程
    * <https://www.mql5.com/zh/articles/407>
{% include image.html url="/assets/images/220416-opencl/20220422120039.png" %}

```cpp
void test() {

    const cl_uint num_entries = 100;
    const size_t param_value_size = 100;

    cl_platform_id platforms[num_entries];
    cl_uint num_platforms = 0;
    clGetPlatformIDs(num_entries, platforms, &num_platforms);

    for (int i = 0; i < num_platforms; i++) {
        cl_platform_id platform = platforms[i];
        cl_platform_info param_name = CL_PLATFORM_NAME;

        char param_valuep[param_value_size];
        size_t param_value_size_ret = 0;

        clGetPlatformInfo(platform,
            param_name,
            param_value_size,
            param_valuep,
            &param_value_size_ret);

        cl_device_type device_type = CL_DEVICE_TYPE_ALL;
        cl_device_id devices[num_entries];
        cl_uint num_devices = 0;

        clGetDeviceIDs(platform,
            device_type,
            num_entries,
            devices,
            &num_devices);

        for (int j = 0; j < num_devices; j++) {

            cl_device_id device = devices[j];
            cl_device_info param_name = CL_DEVICE_NAME;

            char param_valued[param_value_size];
            size_t param_value_size_ret = 0;

            clGetDeviceInfo(device,
                param_name,
                param_value_size,
                param_valued,
                &param_value_size_ret);
            param_value_size_ret = 0; //
        }

    }
}
```

Intel(R) OpenCL HD Graphics
Intel(R) HD Graphics 630


## 存储模型

OpenCL 将设备中的内部存储器抽象成四层结构的存储模型：
1. **全局内存（global memory）**：同一个工作空间内的所有工作节点都可以进行读写，宿主机可以对其进行初始化，特点是存储容量大、访问速度慢。
2. **常量内存（constant memory）**：工作空间内所有工作节点都可以进行读操作，却不能进行写操作。由宿主机进行初始化，在 kernel 执行过程中保持不变。
3. **本地内存（local memory）**：同一个工作组中所有的工作节点都可以进行读写操作，对其他工作组内的工作节点不可见，不可以通过宿主机进行初始化。
4. **私有内存（private memory）**：工作节点的专属内存，对其他工作节点完全不可见，只能通过内核程序分配。

下表描述了宿主机和设备对内存的的分配和访问规则。
{% include image.html url="/assets/images/220416-opencl/20190225170333694.png" %}
{% include image.html url="/assets/images/220416-opencl/20190225170549160.png" %}

在运行 OpenCL 应用时，宿主机需要将待处理的数据送到 OpenCL 设备，OpenCL 设备运算完成后需要把结构返回给宿主机，这就需要在宿主机与 OpenCL 设备之间进行数据交互，这种交互有两种方式：拷贝数据法和内存映射法。
OpenCL 规定了一个松散的内存模型，它不保证所有的工作节点访问的内存状态是一致的，它只规定在一个工作节点内部访问内存必须是一致的；在工作组内，可以通过同步点来保证组内节点的内存访问一致性。在不同工作组的访问内存一致性上，OpenCL 不提供任何保证。


## OpenCL vs CUDA

OpenCL 和 nVidia CUDA 很像。

CUDA               | OpenCL
---- | ----
Thread             | Work-item
Thread block       | Work-group
global memory      | global memory
constant memory    | constant memory
shared memory      | local memory
local memory       | private memory
Grid size          | Global range
Block size         | Local range
\_\_global\_\_     | kernel
gridDim.x          | get_num_groups(0)
blockDim.x         | get_local_size(0)
blockIdx.x         | get_group_id(0)
threadIds.x        | get_local_id(0)
\_\_syncthreads    | barrier()
warp               | no equivalent


## OpenCL 基本原理

1. 准备 OpenCL 源码（C99）然后给 OpenCL。
2. OpenCL 针对目标设备，编译源码。
3. 向目标设备传输数据。（内存 到 显存）
4. 在数据上运行 kernel。（GPU 运行）
5. 把数据拖回来。（显存 到 内存）


## OpenCL C++ 伪码

```cpp
#include <cl/cl.hpp>
#include <vector>

using namespace cl;
using namespace std;

int main(int, char**)
{
    Platform platform = Platform::getDefault();

    vector<Device> devices;
    platform.getDevices(CL_DEVICE_TYPE_ALL, &devices);

    Context context(devices[0]);
    CommandQueue queue(context, devices[0]);

    Program program(context, "OpenCL C code goes here...");
    program.build();

    auto kernel = make_kernel<Buffer, Buffer>(program, "example_kernel");

    const static int Size = 1000000;
    vector<int> inputData(Size, 0), outputData(Size, 0);

    Buffer inputBuffer(context, CL_MEM_READ_ONLY, Size * sizeof(int));
    Buffer outputBuffer(context, CL_MEM_WRITE_ONLY, Size * sizeof(int));

    // 发送数据
    queue.enqueueWriteBuffer(inputBuffer, false, 0, Size * sizeof(int), inputData.data());

    // 运行 kernel
    kernel(EnqueueArgs(queue, NDRange(Size)), inputBuffer, outputBuffer);

    // 拖回数据
    queue.enqueueReadBuffer(outputBuffer, false, 0, Size * sizeof(int), outputData.data());

    queue.finish();

    return 0;
}
```


## 内核程序 OpenCL C

```c
kernel void example_kernel(global int * input, global int * output)
{
    int worker_id = get_global_id(0);

    output[worker_id] = input[worker_id] + 10 + worker_id;
}

#define MACRO(a, b) a + b

bool function(int a)
{
    float4 vector_type(0, 1, 2, 3); // 有的支持 SIMD

    vector_type *= 2;

    float v = vector_type.x; // 和 OpenGL 有点类似
    float2 v2; float8 v8; float16 v16;
    uchar uc; uint ui;

    local bool local_buffer[256]; // local 内存不能初始化。
    int lid = get_local_id(0);
    if (lid < 256)
        local_buffer[lid] = (uc8.S1 == uc);

    barrier(CLK_LOCAL_MEM_FENCE);

    if (lid < 256 && lid > 1)
        return local_buffer[lid - 1];

    return false;
}
```


## OpenCL 性能优化

* 提前编译一次，再多次使用。
* 数据传输，只传必要的，只需要的时候才传。
* 运算能力往往高于带宽，kernel 拷贝到 local array 快于读取 global memory。
    * **Global data access** Devices generally have more compute power than they have global memory bandwith
        kernels that read multiple values from global memory can be accelerated by copying the data in a local array
* 简单的多个 kernels 序列，性能不如一个大 kernel 直接一次运算。超大 kernel 可能会超出 硬件能力。
    * A sequence of simple kernels will perform less than one kernel doing all the calculations at once.
        But a very big kernel can suffer from private or local memory exhaustion on some devices and will have less performance
        (this is usually not a problem except for very complex algorithms).

* GPU 内存与 CPU 内存有所区别。利用 OpenCL 进行程序性能优化的主要目标，是确保最大化带宽，而非像在 CPU 上一样缩短延迟。
* 存储访问的本质，对于总线利用的效率影响巨大。总线使用率低即意味着运行速度低。
* 要改善代码的性能，存储访问最好是相干的。此外，最好也要避免库冲突。
* 硬件规格（总线宽度、存储库数量，以及可以合并为单一相干访问的线程数量）请见供应商提供的相关文档。


## 性能对比

实现图片模糊，对比性能。

E:\kpdf\fastimage\fastpdf-turbo\gpuip\build\test\Release\test_performance.exe
E:\kpdf\fastimage\fastpdf-turbo\gpuip\examples\images\bridge.exr
E:\kpdf\fastimage\fastpdf-turbo\gpuip\examples\kernels\

```
---------------------------------------------------------------
|                  LERP                                       |
---------------------------------------------------------------
CPU:    33.6 ms.
CPU MT: 216.8 ms.
OpenCL: 4.5 ms, Process 0.8 ms (16.8%), Copy 3.7 ms (83.2%)
GLSL:   23.8 ms, Process 0.7 ms (2.8%), Copy 23.1 ms (97.2%)
---------------------------------------------------------------
|                  BOX BLUR                                   |
---------------------------------------------------------------
CPU:    3491.4 ms.
CPU MT: 983.1 ms.
OpenCL: 5.7 ms, Process 4.9 ms (85.5%), Copy 0.8 ms (14.5%)
GLSL:   5.1 ms, Process -1.0 ms (-19.5%), Copy 6.1 ms (119.5%)
---------------------------------------------------------------
|                  GAUSSIAN BLUR                              |
---------------------------------------------------------------
CPU:    4601.4 ms.
CPU MT: 178.7 ms.
OpenCL: 9.2 ms, Process 8.5 ms (91.5%), Copy 0.8 ms (8.5%)
GLSL:   11.4 ms, Process -1.0 ms (-8.7%), Copy 12.4 ms (108.7%)
---------------------------------------------------------------
|                  SEPARABLE GAUSSIAN BLUR                    |
---------------------------------------------------------------
CPU:    838.0 ms.
CPU MT: 624.9 ms.
OpenCL: 1.8 ms, Process 1.1 ms (59.4%), Copy 0.7 ms (40.6%)
GLSL:   1.7 ms, Process -1.0 ms (-57.5%), Copy 2.7 ms (157.5%)
```

简单的事情 CPU MT 比 CPU 更慢；
GLSL 传输比 OpenCL 更慢。（也有可能是程序没写好 [惭愧]-_-）

普通指令集 vs 增强指令集

* LERP

<table class="tablestyle" ntablew="1:3:3"></table>

CPU |    20.0 ms. | 9.4 ms.
CPU MT | 946.8 ms. | 660.6 ms.
OpenCL | 6.5 ms, Process 0.8 ms (12.0%), Copy 5.7 ms (88.0%) | 2.2 ms, Process 0.7 ms (31.1%), Copy 1.5 ms (68.9%)

* BOX BLUR

<table class="tablestyle" ntablew="1:3:3"></table>

CPU |    1207.2 ms. | 1341.0 ms.
CPU MT | 619.2 ms. | 872.4 ms.
OpenCL | 5.9 ms, Process 5.0 ms (85.3%), Copy 0.9 ms (14.7%) | 5.6 ms, Process 4.8 ms (87.2%), Copy 0.7 ms (12.8%)

* GAUSSIAN BLUR

<table class="tablestyle" ntablew="1:3:3"></table>

CPU |    1983.4 ms. | 3481.0 ms.
CPU MT | 96.4 ms. | 233.0 ms.
OpenCL | 9.4 ms, Process 8.6 ms (91.0%), Copy 0.8 ms (9.0%) | 9.4 ms, Process 8.6 ms (90.9%), Copy 0.9 ms (9.1%)

* SEPARABLE GAUSSIAN BLUR

<table class="tablestyle" ntablew="1:3:3"></table>

CPU |    385.2 ms. | 813.4 ms.
CPU MT | 667.9 ms. | 773.2 ms.
OpenCL | 1.9 ms, Process 1.1 ms (59.2%), Copy 0.8 ms (40.8%) | 1.9 ms, Process 1.1 ms (56.7%), Copy 0.8 ms (43.3%)


## AMD APP Samples

AMD 的丰富的示例 Samples from the AMD APP SDK (with OpenCRun support)
[AMD APP Samples {% include relref_github.html %}](https://github.com/OpenCL/AMD_APP_samples)


### 图片拷贝

```c
__constant sampler_t imageSampler = CLK_NORMALIZED_COORDS_FALSE | CLK_ADDRESS_CLAMP | CLK_FILTER_NEAREST;

/* Copy input 2D image to output 2D image */
__kernel void image2dCopy(__read_only image2d_t input, __write_only image2d_t output)
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    uint4 temp = read_imageui(input, imageSampler, coord);

    write_imageui(output, coord, temp);
}

/* Copy input 3D image to 2D image */
__kernel void image3dCopy(__read_only image3d_t input, __write_only image2d_t output)
{
    int2 coord = (int2)(get_global_id(0), get_global_id(1));

    /* Read first slice into lower half */
    uint4 temp0 = read_imageui(input, imageSampler, (int4)(coord, 0, 0));

    /* Read second slice into upper half */
    uint4 temp1 = read_imageui(input, imageSampler, (int4)((int2)(get_global_id(0), get_global_id(1) - get_global_size(1)/2), 1, 0));

    write_imageui(output, coord, temp0 + temp1);
}
```


### sineWave

Simple kernel to modify vertex positions in sine wave pattern.
param data  data in global memory

```c
__kernel
void sineWave(
    __global float4 * pos,
    unsigned int width,
    unsigned int height,
    float time)
{
    unsigned int x = get_global_id(0);
    unsigned int y = get_global_id(1);

    // calculate uv coordinates
    float u = x / (float) width;
    float v = y / (float) height;
    u = u*2.0f - 1.0f;
    v = v*2.0f - 1.0f;

    // calculate simple sine wave pattern
    float freq = 4.0f;
    float w = sin(u*freq + time) * cos(v*freq + time) * 0.5f;

    // write output vertex
    pos[y*width+x] = (float4)(u, w, v, 1.0f);
}
```


### 数据同步控制

```c
#define GROUP_SIZE 64

__constant int mask[] =
{
    1, -1, 2, -2
};
__kernel void MemoryModel(__global int *outputbuffer, __global int *inputbuffer)
{
    __local int localBuffer[GROUP_SIZE];
    __private int result=0;
    __private size_t group_id=get_group_id(0);
    __private size_t item_id=get_local_id(0);
    __private size_t gid = get_global_id(0);

    // Each workitem within a work group initialize one element of the local buffer
    localBuffer[item_id]=inputbuffer[gid];
    // Synchronize the local memory
    barrier(CLK_LOCAL_MEM_FENCE);

    // add 4 elements from the local buffer
    // and store the result into a private variable
    for (int i = 0; i < 4; i++) {
      result += localBuffer[(item_id+i)%GROUP_SIZE];
    }
    // multiply the partial result with a value from the constant memory
    result *= mask[group_id%4];

    // store the result into a buffer
    outputbuffer[gid]= result;
}
```


### 经典的流体模拟

FluidSimulation2D
搞 豹趣魔屏 的时候接触过，再次见到；作者说是 基于 OpenMP 版本改的。

{% include image.html url="/assets/images/220416-opencl/fluidsimulation2d.gif" %}


## Notes

* C++ Wrapper for OpenCL : www.khronos.org/registry/cl/specs/opencl-cplusplus-1.2.pdf
* OpenCL Reference : www.khronos.org/registry/cl/sdk/1.2/docs/man/xhtml/
* Quick reference card : www.khronos.org/registry/cl/sdk/1.2/docs/OpenCL-1.2-refcard.pdf
* Complete OpenCL tutorial : www.cmsoft.com.br/index.php?option=com_content&view=category&layout=blog&id=41&Itemid=75


## OpenCL <https://man.opencl.org/>


### Debug\binaries.exe

This sample intends to demonstrate how to use separate compilation and consumption of OpenCL program by saving and loading program binaries.

该示例旨在通过**保存**和**加载**程序二进制文件来演示如何使用 OpenCL 程序的单独**编译**和**使用**。


### Debug\blur.exe

This sample intends to demonstrate how to use different techniques of data exchange between workitems in workgroup,
query various extensions applicable and use compile options to touch up kernel sources at runtime to produce the best kernel implementation for the task.

该示例旨在演示如何在工作组中的工作项之间使用**不同的数据交换技术**，
查询各种适用的扩展并使用编译选项在**运行时修改内核源代码**，从而为任务生成最佳内核实现。


### Debug\copybuffer.exe

In this very simple sample, OpenCL APIs are used to copy the contents of one buffer to another buffer on the OpenCL device.
To do this, OpenCL APIs are used to create both buffers, to create the OpenCL command queue, and to initialize the source buffer and verify the contents of the destination buffer on the host.
By default, this sample will run in the first enumerated OpenCL device on the first enumerated OpenCL platform.
To run on a different OpenCL device or platform, please use the provided command line options.

在这个非常简单的示例中，OpenCL API 用于将一个缓冲区的**内容复制**到 OpenCL 设备上的另一个缓冲区。
为此，OpenCL API 用于创建两个缓冲区、创建 OpenCL 命令队列、初始化源缓冲区并验证主机上目标缓冲区的内容。
默认情况下，此示例将在第一个枚举 OpenCL 平台上的第一个枚举 OpenCL 设备中运行。
要在不同的 OpenCL 设备或平台上运行，请使用提供的命令行选项。


### Debug\copybufferkernel.exe

This example uses an OpenCL kernel to do work.
An OpenCL kernel is a short program defining what one OpenCL work item should do.
In this case, each OpenCL work item will copy one value from a source buffer to a destination buffer.
Since this sample launches one work item for every element in the source buffer, behaviorally this sample will do exactly the same thing as the copy buffer sample.
In this sample, the source code for the OpenCL kernel is embedded into the host code as a raw string.
At runtime, an OpenCL program is created from the raw string, and the OpenCL device compiler is invoked to compile the OpenCL program for the OpenCL device.
This isn't the only way to create OpenCL programs, but it is fairly common, especially while learning and developing an OpenCL application.
By default, this sample will run in the first enumerated OpenCL device on the first enumerated OpenCL platform.
To run on a different OpenCL device or platform, please use the provided command line options.

此示例使用 OpenCL 内核来完成工作。
OpenCL 内核是一个简短的程序，它定义了一个 OpenCL 工作项应该做什么。
在这种情况下，每个 OpenCL 工作项会将一个值从源缓冲区复制到目标缓冲区。
由于此示例为源缓冲区中的每个元素启动一个工作项，因此从行为上讲，此示例将执行与复制缓冲区示例完全相同的操作。
在此示例中，OpenCL 内核的源代码作为原始字符串嵌入到主机代码中。
在运行时，从原始字符串创建 OpenCL 程序，并调用 OpenCL 设备编译器为 OpenCL 设备编译 OpenCL 程序。
这不是创建 OpenCL 程序的唯一方法，但它相当普遍，尤其是在学习和开发 OpenCL 应用程序时。
默认情况下，此示例将在第一个枚举 OpenCL 平台上的第一个枚举 OpenCL 设备中运行。
要在不同的 OpenCL 设备或平台上运行，请使用提供的命令行选项。


### Debug\enumopencl.exe

This is a very simple sample that demonstrates how to enumerate the OpenCL platforms that are installed on a machine, and the OpenCL devices that these platforms expose.
This is one of the few samples that uses the OpenCL C APIs, as described in the OpenCL specification.
Most of the other samples use the OpenCL C++ API bindings, since they make it a lot easier to write and understand OpenCL code!
This is a good first sample to run to verify that OpenCL is correctly installed on your machine, and that your build environment is correctly setup.

这是一个非常简单的示例，演示了如何枚举安装在机器上的 OpenCL 平台，以及这些平台公开的 OpenCL 设备。
这是使用 OpenCL C API 的少数示例之一，如 OpenCL 规范中所述。
大多数其他示例都使用 OpenCL C++ API 绑定，因为它们使编写和理解 OpenCL 代码变得更加容易！
这是一个很好的第一个示例，可以运行以验证 OpenCL 是否正确安装在您的机器上，以及您的构建环境是否正确设置。


### Debug\reduce.exe & reducecpp.exe

This sample intends to demonstrate how to query various extensions applicable in the context of a reduction algorithm, touch up kernel sources at runtime to select the best kernel implementation for the task.

此示例旨在演示如何查询适用于缩减算法的各种扩展，在运行时修改内核源以选择任务的最佳内核实现。


### Debug\saxpy.exe & saxpycpp.exe

This sample intends to be a minimal end-to-end OpenCL application doing actual device-side computation. The structure of the sample rhymes well with the How Does OpenCL Work? chapter of the OpenCL-Guide, particularly the Executing an OpenCL Program part.
This sample is implemented using both C and C++ languages to demonstrate the difference in verbosity when using the naked C bindings compared to the C++ wrapper.

此示例旨在成为执行实际设备端计算的最小端到端 OpenCL 应用程序。示例的结构与 OpenCL 如何工作？ OpenCL 指南的章节，特别是执行 OpenCL 程序部分。
此示例是使用 C 和 C++ 语言实现的，以展示使用裸 C 绑定与 C++ 包装器相比在详细程度方面的差异。


### Debug\conwaycpp.exe 扩展

This sample intends to demonstrate how to share images (textures) between OpenCL and OpenGL. How Does OpenCL-OpenGL Interop? chapter of the OpenCL-Guide lays out the fundamentals of OpenCL-OpenGL interoperability.

此示例旨在演示如何在 OpenCL 和 OpenGL 之间共享图像（纹理）。 OpenCL-OpenGL 如何互操作？ OpenCL 指南的第 1 章阐述了 OpenCL-OpenGL 互操作性的基础知识。


### Debug\histogramcpp.exe 扩展

The sample calculate the histogram of a random sequence with global atomic add and when it is possible, it's using local atomic add.

This sample intends to be a minimal end-to-end OpenCL application doing actual device-side computation. The structure of the sample rhymes well with the How Does OpenCL Work? chapter of the OpenCL-Guide, particularly the Executing an OpenCL Program part.
This sample is implemented using C++ languages.

该示例使用全局原子添加计算随机序列的直方图，并且在可能的情况下，它使用局部原子添加。

此示例旨在成为执行实际设备端计算的最小端到端 OpenCL 应用程序。示例的结构与 OpenCL 如何工作？ OpenCL 指南的章节，特别是执行 OpenCL 程序部分。
此示例使用 C++ 语言实现。


### Debug\nbodycpp.exe 扩展

This sample intends to demonstrate how to share (vertex) buffers between OpenCL and OpenGL. How Does OpenCL-OpenGL Interop? chapter of the OpenCL-Guide lays out the fundamentals of OpenCL-OpenGL interoperability.

此示例旨在演示如何在 OpenCL 和 OpenGL 之间共享（顶点）缓冲区。 OpenCL-OpenGL 如何互操作？ OpenCL 指南的第 1 章阐述了 OpenCL-OpenGL 互操作性的基础知识。


### Debug\cargstest.exe

A simple argument parser library

<https://github.com/likle/cargs.git>


### OpenCL-CLHPP

* Debug\headerexample.exe OpenCL-CLHPP
* Debug\trivial.exe OpenCL-CLHPP
* Debug\trivialSizeTCompat.exe OpenCL-CLHPP

<http://khronosgroup.github.io/OpenCL-CLHPP/>

对于许多大型应用程序，C++ 是首选语言，因此为 OpenCL 定义 C++ 绑定似乎是合理的。

该接口包含在单个 C++ 头文件 opencl.hpp 中，所有定义都包含在命名空间 cl 中。不需要包含 cl.h 并使用 C++ 或原始 C 绑定；只需包含 opencl.hpp 就足够了。

绑定本身是轻量级的，并且与底层 C API 密切对应。使用 C++ 绑定不会引入额外的执行开销。

新标头中有许多兼容性、可移植性和内存管理修复以及其他 OpenCL 2.0 功能。因此，标头不能直接向后兼容，因此我们将其作为 opencl.hpp 而不是新版本的 cl.hpp 发布。


### OpenCLUtils.lib & OpenCLUtilsCpp.lib

OpenCL SDK 中有两个库，所有示例都在不同程度上使用它们。一个这样的库是 OpenCL 实用程序库，它是一个导出库，旨在简化 OpenCL 的使用，而 OpenCL SDK 库构建在它之上，但在安装 SDK 时不会导出。 OpenCL SDK 库以在 SDK 示例上下文之外可能没有意义的方式扩展了实用程序库。

One may think of this library as analogous to GLU and GLUT in the domain of OpenGL. A set of utilities which condense common tasks into singular functions or add missing functionality of the API which otherwise couldn't be added as a non-API-breaking change.
For a complete list utilities provided by this library, refer to the OpenCL Utility Library docs.

The OpenCL Utility Library provides both C and C++ bindings with near feature parity. The utilities are broken into to libraries, OpenCLUtils and OpenCLUtilsCpp.
To include them in your project, include \<CL/Utils/Utils.h\>/\<CL/Utils/Utils.hpp\> and link to their libraries respectively.

OpenCL 实用程序库提供具有接近功能奇偶性的 C 和 C++ 绑定。这些实用程序分为库、OpenCLUtils 和 OpenCLUtilsCpp。
要将它们包含在您的项目中，请包含 \<CL/Utils/Utils.h\>/\<CL/Utils/Utils.hpp\> 并分别链接到它们的库。


### OpenCLSDK.lib & OpenCLSDKCpp.lib

The SDK library extends the Utility library by deduplicating common tasks like command-line argument parsing, selecting devices, logging, and other contentious tasks which your application likely does differently, hence the value in shipping it for external use, moreover promise forward and/or backward compatibility is low.
For a complete list functionality provided by this library, refer to the OpenCL SDK Library docs.

The OpenCL SDK Library hosts both C and C++ utilities which are generally useful for writing OpenCL applications but are either dependency-heavy or contentious. Because these utilities aren't the subject of universal interest, these utilities are not exported, meaning SDK installations won't install their headers nor their libraries. Doing so the OpenCL Utility Library can be kept dependency-free.
The utilities are broken into to libraries, OpenCLSDK and OpenCLSDKCpp. Samples include \<CL/Utils/Utils.h\>/\<CL/Utils/Utils.hpp\> and link to their libraries respectively.

OpenCL SDK 库包含 C 和 C++ 实用程序，这些实用程序通常对编写 OpenCL 应用程序很有用，但依赖关系严重或有争议。
因为这些实用程序不是普遍感兴趣的主题，所以不会导出这些实用程序，这意味着 SDK 安装不会安装它们的头文件或库。这样做可以使 OpenCL 实用程序库保持无依赖关系。
这些实用程序分为库、OpenCLSDK 和 OpenCLSDKCpp。示例包括 \<CL/Utils/Utils.h\>/\<CL/Utils/Utils.hpp\> 并分别链接到它们的库。


## 骚操作


### 选择显卡 vendor

我电脑存在多个 GPU，优先 英伟达、AMD、Intel，其它就无所谓了。
<https://pci-ids.ucw.cz/>
完整表格：<https://pci-ids.ucw.cz/v2.2/pci.ids>

```cpp
#define OPENCL_VENDOR_NVIDIA 4318 // 0x10de NVIDIA Corporation
#define OPENCL_VENDOR_AMD1   4098 // 0x1002 Advanced Micro Devices, Inc. [AMD/ATI]
#define OPENCL_VENDOR_AMD2   4130 // 0x1022 Advanced Micro Devices, Inc. [AMD]
#define OPENCL_VENDOR_INTEL 32902 // 0x8086 Intel Corporation
#define OPENCL_VENDOR_VMWARE 0x15ad // 0x15ad VMware
```
{% include image.html url="/assets/images/220416-opencl/20220430225733.png" caption="我 DELL 游戏本的参数" %}
{% include image.html url="/assets/images/220416-opencl/20220502004338.png" caption="我 Mac Mini 参数" %}



<hr class='reviewline'/>
<p class='reviewtip'><script type='text/javascript' src='{% include relref.html url="/assets/reviewjs/blogs/2022-04-16-opencl.md.js" %}'></script></p>
<font class='ref_snapshot'>参考资料快照</font>

- [https://www.khronos.org/opencl/]({% include relrefx.html url="/backup/2022-04-16-opencl.md/www.khronos.org/299e65e9.html" %})
- [https://www.bookstack.cn/read/Heterogeneous-Computing-with-OpenCL-2.0/content-chapter2-2.2-chinese.md]({% include relrefx.html url="/backup/2022-04-16-opencl.md/www.bookstack.cn/52bc81a0.html" %})
- [https://www.mql5.com/zh/articles/405]({% include relrefx.html url="/backup/2022-04-16-opencl.md/www.mql5.com/6159139e.html" %})
- [https://www.mql5.com/zh/articles/407]({% include relrefx.html url="/backup/2022-04-16-opencl.md/www.mql5.com/2054dd8f.html" %})
- [https://github.com/OpenCL/AMD_APP_samples]({% include relrefx.html url="/backup/2022-04-16-opencl.md/github.com/c832c544.html" %})
- [https://man.opencl.org/]({% include relrefx.html url="/backup/2022-04-16-opencl.md/man.opencl.org/ccb09132.html" %})
- [https://github.com/likle/cargs.git]({% include relrefx.html url="/backup/2022-04-16-opencl.md/github.com/2a647c7e.html" %})
- [http://khronosgroup.github.io/OpenCL-CLHPP/]({% include relrefx.html url="/backup/2022-04-16-opencl.md/khronosgroup.github.io/64069589.html" %})
- [https://pci-ids.ucw.cz/]({% include relrefx.html url="/backup/2022-04-16-opencl.md/pci-ids.ucw.cz/93a6ba4f.html" %})
