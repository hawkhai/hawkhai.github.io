---
layout: post
title: "图像处理 -- OpenCV 4.1.2 文档整理"
author:
location: "珠海"
categories: ["图像处理"]
tags: ["OpenCV", "图像处理"]
toc: true
toclistyle:
comments:
visibility:
mathjax: true
mermaid:
glslcanvas:
codeprint:
---

OpenCV 4.1.2 文档整理，把整个文档都阅读整理了一遍。

[wechatdl](http://localhost:4000/blog/source/wechatdl/wechatdl)
[OpenCV-Python Tutorials 官方文档](https://docs.opencv.org/4.1.2/d6/d00/tutorial_py_root.html)

[OpenCV 中文文档 4.0.0](https://www.bookstack.cn/read/opencv-doc-zh-4.0/README.md)

[OpenCV-Python 中文指南专栏开篇 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484061&idx=1&sn=ffa6b8ae8b497442e99186656c70838b&chksm=fcbbfa67cbcc737101bbd8c3c9bd4c34d9564284758aba6341c632c986b00b3b2fac991a52f1&scene=27)


## [OpenCV-Python 教程简介 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484066&idx=1&sn=aeddfb9625fe9f2bd1ef23b0e409ad41&chksm=fcbbfa58cbcc734eff809ba6dee3f1dba33f57d3544f50c83c7aa152b2f0447bcbca968fad5d&scene=27)

* OpenCV 中的 GUI 特性 Gui Features in OpenCV
    * 在这里，如何显示和保存图像和视频，控制鼠标事件以及创建轨迹栏（trackbar）。
* 核心操作 Core Operations
    * 图像的基本操作、例如像素编辑、几何变换，代码优化、一些数学工具等。
* OpenCV 中的图像处理 Image Processing in OpenCV
    * OpenCV 内部的不同图像处理函数。
* 特征检测与描述 Feature Detection and Description
    * 有关特征检测和描述符的信息
* 视频分析 Video analysis (video module)
    * 在本部分中，与对象跟踪等视频配合使用的不同技术。
* 相机校准和 3D 重建 Camera Calibration and 3D Reconstruction
    * 有关相机校准，立体成像（stereo imaging）等的信息。
* 机器学习 Machine Learning
    * OpenCV 内部的不同图像处理函数。
* 计算摄影学 Computational Photography
    * 不同的计算摄影技术如图像去噪（denoising）等。
* 目标检测（objdetect 模块） Object Detection (objdetect module)
    * 目标检测技术，例如人脸检测等。
* OpenCV-Python Binding OpenCV-Python Bindings
    * 我们将了解如何生成 OpenCV-Python Binding


## [在 Fedora 中安装 OpenCV-Python {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484072&idx=1&sn=d0240c5954f3a0bf99e4c5460a919a81&chksm=fcbbfa52cbcc734433f0a9b9a133e2e6706a1ea879c798ce60b7c145ff6c1b87e7678776e0f5&scene=27)

启用 TBB 和 Eigen 支持：
```
cmake -D WITH_TBB=ON -D WITH_EIGEN=ON ..
```


### OpenCV 收费模块的使用

OpenCV 是由英特尔公司发起并参与开发，以 BSD 许可证授权发行，可以在商业和研究领域中免费使用。

加入这个头文件即可（还有相应的 lib 文件）
```
#include "opencv2/nonfree/nonfree.hpp"
```


### OpenCV 对 TBB 的支持

<https://github.com/oneapi-src/oneTBB>
oneAPI Threading Building Blocks (oneTBB) lets you easily write parallel C++ programs that take full advantage of multicore performance, that are portable, composable and have future-proof scalability.

用 CMake 生成的时候实际上是在文件 cvconfig.h 里写上了：
```
#define HAVE_TBB
cmake .. -G "Visual Studio 16 2019" -A Win32 -D WITH_TBB=ON -D WITH_OPENMP=ON -D OPENCV_FORCE_3RDPARTY_BUILD=ON
ONETBB(1000); TBB(990); OPENMP(980)
opencv_core_parallel_onetbb453d.dll => FAILED
opencv_core_parallel_tbb453d.dll => FAILED
opencv_core_parallel_openmp453d.dll => FAILED
D:\2021\opencv_liebao\4.5.3\

parallel\registry_parallel.impl.hpp (96)
    cv::parallel::ParallelBackendRegistry::ParallelBackendRegistry core(parallel):
    Enabled backends(3, sorted by priority): ONETBB(1000); TBB(990); OPENMP(980)
utils\plugin_loader.impl.hpp (67) load opencv_core_parallel_onetbb453d.dll => FAILED
utils\plugin_loader.impl.hpp (67) load opencv_core_parallel_tbb453d.dll => FAILED
utils\plugin_loader.impl.hpp (67) load opencv_core_parallel_openmp453d.dll => FAILED
```

这几行错误提示有毒，一直以为这个世界上存在 `opencv_core_parallel_tbb453d.dll` 这种东西，直到看了源码，是静态编译进去的。

```cmake
#if defined HAVE_TBB
#  define CV_PARALLEL_FRAMEWORK "tbb"
#elif defined HAVE_HPX
#  define CV_PARALLEL_FRAMEWORK "hpx"
#elif defined HAVE_OPENMP
#  define CV_PARALLEL_FRAMEWORK "openmp"
#elif defined HAVE_GCD
#  define CV_PARALLEL_FRAMEWORK "gcd"
#elif defined WINRT
#  define CV_PARALLEL_FRAMEWORK "winrt-concurrency"
#elif defined HAVE_CONCURRENCY
#  define CV_PARALLEL_FRAMEWORK "ms-concurrency"
#elif defined HAVE_PTHREADS_PF
#  define CV_PARALLEL_FRAMEWORK "pthreads"
#endif
```

```cpp
static
std::vector<ParallelBackendInfo>& getBuiltinParallelBackendsInfo()
{
    static std::vector<ParallelBackendInfo> g_backends
    {
#ifdef HAVE_TBB
        DECLARE_STATIC_BACKEND("TBB", createParallelBackendTBB)
#elif defined(PARALLEL_ENABLE_PLUGINS)
        DECLARE_DYNAMIC_BACKEND("ONETBB")   // dedicated oneTBB plugin (interface >= 12000, binary incompatibe with TBB 2017-2020)
        DECLARE_DYNAMIC_BACKEND("TBB")      // generic TBB plugins
#endif

#ifdef HAVE_OPENMP
        DECLARE_STATIC_BACKEND("OPENMP", createParallelBackendOpenMP)
#elif defined(PARALLEL_ENABLE_PLUGINS)
        DECLARE_DYNAMIC_BACKEND("OPENMP")  // TODO Intel OpenMP?
#endif
    };
    return g_backends;
};
```


## [在 Ubuntu 中安装 OpenCV-Python {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484077&idx=1&sn=f8ac89b218addfe8b4110b8dfa121938&chksm=fcbbfa57cbcc7341eafaff4fc3b9e7295bbcd3de59af8e62cfdf945841265b5f001da2cfea5d&scene=27)


## [在 Windows 中安装 OpenCV-Python {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484085&idx=1&sn=8c3757c43f7f6b9eef2f2b7429bf0239&chksm=fcbbfa4fcbcc7359b6ee51c9b287968d0a9e7149c4b4e30cd4d212a6f4c4829504ec2f4c43af&scene=27)


## [图像入门 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484091&idx=1&sn=02c16e0f2542f046f63cb6be58fb924e&chksm=fcbbfa41cbcc7357fa3287dd01371a481243ae0909e279dff2db31b99914be34edabb33f871f&scene=27)


## [视频处理入门 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484103&idx=1&sn=e99db504871588b099656c6599b0bf8e&chksm=fcbbfa3dcbcc732b6a19aeaba6ccef4c630b7e86f7ca202e2fa9102de9885926dbc991cc6ecd&scene=27)


## [OpenCV 中的绘图功能 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484108&idx=1&sn=1bcb7b08d1d908ab78c8ff5dbf0ef425&chksm=fcbbfa36cbcc732053bc9e6ed67f0b2e73d92bc9c3ce32161ce046e0240ed92c37513d0dbd1c&scene=27)


## [鼠标作为画笔 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484113&idx=1&sn=d0850427801acd2046e7c053a3b27892&chksm=fcbbfa2bcbcc733d00eb7804620dc4e5aa96a302f52d516fa8696987dff4bece6a65727f2131&scene=27)


## [轨迹栏作为调色板 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484124&idx=1&sn=cd813259638c119e26b6d3502aea12c2&chksm=fcbbfa26cbcc7330bb3ee3bd8d75edbc1575ababdbde826baf0d6739f51f6e3d7fc6fcf17f29&scene=27)


## [图像的基本操作 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484172&idx=1&sn=ee9b3ac19e45337b1a7551db17cb2340&chksm=fcbbfbf6cbcc72e09c66fb0d1000bd6b0faaa87da5990cdac2c64253ac3ca66dea2244b1f411&scene=27)


## [图像上的算术运算 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484185&idx=1&sn=a58869d5ce3160656e239f800f92cb3e&chksm=fcbbfbe3cbcc72f50eed235dc6e67fdf779ac99302c72953a4da6a24ac96d1a75b9fee621299&scene=27)

OpenCV 加法和 Numpy 加法之间有区别。OpenCV 加法是饱和运算，而 Numpy 加法是模运算。

```python
>>> x = np.uint8([250])
>>> y = np.uint8([10])
>>> print( cv.add(x,y) ) # 250+10 = 260 => 255
[[255]]
>>> print( x+y )         # 250+10 = 260 % 256 = 4
[4]
```


### 图像逻辑运算

* cv2.add()；
* cv2.addWeighted()；
* cv2.subtract()；
* cv2.absdiff()；
* cv2.bitwise_and()；
* cv2.bitwise_not()；
* cv2.bitwise_xor()。


## [OpenCV 4.1.2 之性能衡量与优化方法 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484194&idx=1&sn=93077ea07afe5bb7053912fcb66da235&chksm=fcbbfbd8cbcc72ce1fdaf77aa1566170f8a1c1083a3ad7efa7cca875a7798ef14608105f18d1&scene=27)


### OpenCV 中的默认优化

许多 OpenCV 函数都是使用 SSE2、 AVX 等进行优化的。
你可以使用 cvUseoptimized 检查是否启用 / 禁用和 cvSetuseoptimized 以启用 / 禁用它。


### 性能优化技术

首先尝试以一种简单的方式实现算法。一旦它运行起来，分析它，找到瓶颈并优化它们。
1. 尽量避免在 Python 中使用循环，尤其是双 / 三重循环等。它们本来就很慢。
2. 由于 Numpy 和 OpenCV 已针对向量运算进行了优化，因此将算法 / 代码向量化到最大程度。
3. 利用缓存一致性。
4. 除非需要，否则切勿创建数组的副本。尝试改用视图。数组复制是一项昂贵的操作。


## [改变颜色空间 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484199&idx=1&sn=a02f8b22ae725939840f24ce5bc0bcf3&chksm=fcbbfbddcbcc72cb05066f3f65c9352f6e2e72449710b66a32c8a0f5775b01a0031ece7079e5&scene=27)

HSV 的色相范围为 [0, 179]，饱和度范围为 [0, 255]，值范围为 [0, 255]。

对象追踪：
```python
import cv2 as cv
import numpy as np
cap = cv.VideoCapture(0)
while (1):
    # 读取帧
    _, frame = cap.read()
    # 转换颜色空间 BGR 到 HSV
    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)
    # 定义 HSV 中蓝色的范围
    lower_blue = np.array([110,50,50])
    upper_blue = np.array([130,255,255])
    # 设置 HSV 的阈值使得只取蓝色
    mask = cv.inRange(hsv, lower_blue, upper_blue)
    # 将掩膜和图像逐像素相加
    res = cv.bitwise_and(frame, frame, mask=mask)
    cv.imshow('frame',frame)
    cv.imshow('mask',mask)
    cv.imshow('res',res)
    k = cv.waitKey(5) & 0xFF
    if k == 27:
        break
cv.destroyAllWindows()
```


## [图像的几何变换 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484215&idx=1&sn=bbba992133e40f50cce402ad025b440d&chksm=fcbbfbcdcbcc72db9308804264569e5ad81a5d9a01ed5fb93707e323df7a14206a943be522d7&scene=27)

平移、旋转、仿射变换等。

旋转或移动图像

```python
def rotate(img, angle, center=None):
    w, h = img.shape[:2]
    if center == None:
        center = (w//2, h//2)
        # center is the center of image from which we have to rotate
        # if it is None then it is cconsider as the center of the original image.
    rotMat = cv.getRotationMatrix2D(center, angle, 1.0)
    dim = (w, h)
    return cv.warpAffine(img, rotMat, dim)
```

* 图像缩放 cv2.resize()；
* 图像平移 cv2.warpAffine()；
* 图像旋转 cv2.getRotationMatrix2D()；
* 图像转置 cv2.transpose()；
* 图像镜像 cv2.flip()；
* 图像重映射 cv2.remap()。


## [图像阈值 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484223&idx=1&sn=e2faf98c93da465415e2dda157028c4a&chksm=fcbbfbc5cbcc72d336a8bba7e9c593f1e98c7cd3cf480320a25f108527efeb58662ca8204d8c&scene=27)


## [图像平滑 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484230&idx=1&sn=ecb5b715d1676119edfdae597039f904&chksm=fcbbfbbccbcc72aae2bedc0f413172e2d2547f4679acad156d1c220fa931cf5cc699d08dac13&scene=27)

OpenCV 主要提供四种类型的模糊技术。
1. 平均 cv.blur() 或 cv.boxFilter()
2. 高斯模糊 cv.GaussianBlur()
3. 中位模糊 cv.medianBlur()
4. 双边滤波 cv.bilateralFilter()


## [形态学转换 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484235&idx=1&sn=a3fb1db63329bdc3ea78fb7a0d863abb&chksm=fcbbfbb1cbcc72a746376fc2175feced558793fc75c06f9991e2d3c131ad1b5543698bc4a478&scene=27)


### 开运算

开运算（MORPH_OPEN）：先腐蚀再膨胀
开放只是侵蚀然后扩张的另一个名称。如上文所述，它对于消除噪音很有用。
opening = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)

{% include image.html url="/assets/images/211106-opencv-4.1.2/640z1.webp" %}


### 闭运算

闭运算（MORPH_CLOSE）：先膨胀再腐蚀
闭运算与开运算相反，先扩张然后再侵蚀。在关闭前景对象内部的小孔或对象上的小黑点时很有用。
closing = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)

{% include image.html url="/assets/images/211106-opencv-4.1.2/640z2.webp" %}


### 形态学梯度

形态梯度（MORPH_GRADIENT）：膨胀图与腐蚀图之差（保留物体边缘轮廓）
**形态学梯度** 这是图像扩张和侵蚀之间的区别。结果将看起来像对象的轮廓。
{% include image.html url="/assets/images/211106-opencv-4.1.2/ac345982b2b7d0a2452c942c4413850c49369a98.jpeg" %}


### 顶帽

顶帽（MORPH_TOPHAT）：原图像与开运算之差
`顶帽运算（image）= 原图（image）- 开运算（image）`
所以顶帽运算得到的实际上是噪声图像。
{% include image.html url="/assets/images/211106-opencv-4.1.2/20200219150629131.png" %}


### 黑帽

黑帽（MORPH_BLACKHAT）：闭图像与原图像之差
`黑帽运算（image）= 闭运算（image）-原图（image）`
实际得到的是前景图中的黑点和小洞。
{% include image.html url="/assets/images/211106-opencv-4.1.2/2020021915190313.png" %}


## [图像梯度 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484242&idx=1&sn=7dcf3f5cad9aaab1898ebec36f57caee&chksm=fcbbfba8cbcc72be1b0ff7572a3f1259cedb4439aeb14319556c6d731a41cf6ccae40dc562a7&scene=27)

查找图像梯度、边缘等。
我们将看到以下函数：cv.Sobel()，cv.Scharr()，cv.Laplacian() 等。
{% include image.html url="/assets/images/211106-opencv-4.1.2/640tidu.webp" %}

梯度（Gradient）定位边缘

```python
# Apply gradient filtering
sobel_x = cv2.Sobel(img, cv2.CV_64F, dx = 1, dy = 0, ksize = 5)
sobel_y = cv2.Sobel(img, cv2.CV_64F, dx = 0, dy = 1, ksize = 5)
blended = cv2.addWeighted(src1=sobel_x, alpha=0.5, src2=sobel_y,
                          beta=0.5, gamma=0)
laplacian = cv2.Laplacian(img, cv2.CV_64F)
```

拉普拉斯运算使用的是 x 和 y 的二阶导数，数学表达式如下。

$$
L(x, y)=\frac{\partial^{2} I}{\partial x^{2}}+\frac{\partial^{2} I}{\partial y^{2}}
$$

OpenCV 中常用的四种模糊效果
* 平均模糊（Averaging blurring）
* 高斯模糊（Gaussian blurring）
* 中值模糊（median blurring）
* 双边滤波（bilateral filtering）
    * 是高斯模糊的一个高级版本。模糊化不仅可以溶解噪声，而且还会平滑边缘。而双边滤波器能在去除噪声的同时保持边缘锐化。这是由于它不仅使用高斯分布值，还同时考虑了距离和像素值的差异。因此，需要指定 sigmaSpace 和 sigmaColor 这两个参数。
    * `cv.bilateralFilter()` 在保持边缘锐利的同时去除噪音非常有效。但与其他过滤器相比，操作速度较慢。


## [Canny 边缘检测 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484249&idx=1&sn=58061fc866bba81da55df8c1f7db0624&chksm=fcbbfba3cbcc72b5828134cf329abb0857e47be15db6f6a7e8e06ba16089d0d354c610fd4737&scene=27)

输入图像为原始图像，thereshold-1 即像素值低于 150 被视为非边缘，threshold-2 即像素值高于 175 被视为有效边缘。
如果该值在 150 和 175 之间，那么如果边缘像素与有效边缘相连，则仅将其视为有效边缘。

```python
cv.Canny(originalImg, 150, 175)
```


## [图像金字塔 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484256&idx=1&sn=5212ffecf620b668598822e6f58d10a9&chksm=fcbbfb9acbcc728c1501f5ac1ea26a48f5dbbc4d21b5551221ae512c380827efa82f45abe698&scene=27)

我们将使用图像金字塔创建一个新的水果“Orapple”。
我们将看到以下功能：cv.pyrUp()，cv.pyrDown()。

有两种图像金字塔。1）高斯金字塔和 2）拉普拉斯金字塔。
拉普拉斯金字塔的层由高斯金字塔的层与高斯金字塔的高层的扩展版本之间的差形成。
{% include image.html url="/assets/images/211106-opencv-4.1.2/640orapple.webp" %}

1. 加载苹果和橙子的两个图像
2. 查找苹果和橙子的高斯金字塔（在此示例中，级别数为 6）
3. 在高斯金字塔中，找到其拉普拉斯金字塔
4. 然后在每个拉普拉斯金字塔级别中加入苹果的左半部分和橙子的右半部分
5. 最后从此联合图像金字塔中重建原始图像。

全景图像拼接 [Image Blending](http://pages.cs.wisc.edu/~csverma/CS766_09/ImageMosaic/imagemosaic.html)


## [轮廓入门 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484261&idx=1&sn=35fd538843bd7d783d3e78a329352b7a&chksm=fcbbfb9fcbcc72890e8aecf199225dcfe7142116b77ef858a2e6a6996a9eeef3eb270e43cdc3&scene=27)

查找轮廓 cv.findContours()，绘制轮廓 cv.drawContours()。


## [轮廓特征 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484268&idx=1&sn=8b1090e7fccf33e6f973858df3a53f49&chksm=fcbbfb96cbcc72807a004f5f80d1ac37fd95ea3d37a9ab33851b072080b816f280ddca893366&scene=27)

* 寻找凸包 cv2.convexHull() 与 凸性检测 cv2.isContourConvex()；
* 轮廓外接矩形 cv2.boundingRect()；
* 轮廓最小外接矩形 cv2.minAreaRect()；
* 轮廓最小外接圆 cv2.minEnclosingCircle()；
* 轮廓椭圆拟合 cv2.fitEllipse()；
* 逼近多边形曲线 cv2.approxPolyDP()；
* 计算轮廓面积 cv2.contourArea()；
* 计算轮廓长度 cv2.arcLength()；
* 计算点与轮廓的距离及位置关系 cv2.pointPolygonTest()；
* 形状匹配 cv2.matchShapes()。


## [轮廓属性 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484281&idx=1&sn=4a1bfd2414e269e10d631eea73c147ca&chksm=fcbbfb83cbcc729509d9a01a0333d733bbe0d6d9b33906c671979131814a9d5747797165210c&scene=27)


## [轮廓：更多属性 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484286&idx=1&sn=896bcc9d66f631d194282929885e3a77&chksm=fcbbfb84cbcc7292ee141ca605ba75d7ba9e839be14c7848be126030a3f110fce9f49f4916f0&scene=27)


## [轮廓分层 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484291&idx=1&sn=af58c28022d21e7d4cdbca75fcb536eb&chksm=fcbbfb79cbcc726f0c200502b51522d9a1464611c0ca24428122d3408fc37dc8ba266ff55e6c&scene=27)


## [直方图-1：查找、绘制和分析 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484296&idx=1&sn=c9980549b844df572d4e798da50f6daf&chksm=fcbbfb72cbcc7264bf4f3aa5d66c2f255ae2da8c17090e83aa969907a51fd0444c679f25fe59&scene=27)

* 直方图均衡化 cv2.equalizeHist()；
* 直方图对比 cv2.compareHist()；
* 反向投影 cv2.calcBackProject()。


## [直方图-2：直方图均衡 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484304&idx=1&sn=f7cd9ae72ab155e3d60b230ffeea1571&chksm=fcbbfb6acbcc727c6a8056c31178ac95556d4426de230754c1f68292f970e4186a887aecfb5e&scene=27)

一般均衡图像的对比度或者亮度。
* **BINS** ：上面的直方图显示每个像素值的像素数，即从 0 到 255。统计数值刻度。
    BINS 由 OpenCV 文档中的 histSize 术语表示。
* **DIMS** ：这是我们为其收集数据的参数的数量。在这种情况下，我们仅收集关于强度值的一件事的数据。所以这里是 1。
* **RANGE** ：这是您要测量的强度值的范围。通常，它是 [0,256]，即所有强度值。

OpenCV 函数比 np.histogram() 快大约 40 倍。因此，尽可能使用 OpenCV 函数。

OpenCV 中的直方图均衡
```python
img = cv.imread('wiki.jpg', 0)
equ = cv.equalizeHist(img)
res = np.hstack((img, equ)) # stacking images side-by-side
cv.imwrite('res.png', res)
```

自适应直方图均衡，CLAHE（对比度受限的自适应直方图均衡）
```python
import numpy as np
import cv2 as cv
img = cv.imread('tsukuba_l.png', 0)
# create a CLAHE object (Arguments are optional).
clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
cl1 = clahe.apply(img)
cv.imwrite('clahe_2.jpg', cl1)
```

{% include image.html url="/assets/images/211106-opencv-4.1.2/1396837-20190220120341669-1864417603.png" %}

在这种情况下，图像被分成称为“tiles”的小块（在 OpenCV 中，tileSize 默认为 8x8）。然后，像往常一样对这些块中的每一个进行直方图均衡。
因此，在较小的区域中，直方图将限制在一个较小的区域中（除非存在噪声）。如果有噪音，它将被放大。
为了避免这种情况，应用了对比度限制。如果任何直方图 bin 超出指定的对比度限制（在 OpenCV 中默认为 40），则在应用直方图均衡之前，
将这些像素裁剪并均匀地分布到其他 bin。均衡后，要消除图块边界中的伪影，请应用双线性插值。


## [直方图-3：二维直方图](https://mp.ofweek.com/bigdata/a145693523076)

对于颜色直方图，我们需要将图像从 BGR 转换为 HSV。
* 对于一维直方图，我们从 BGR 转换为灰度。一维直方图，仅考虑一个特征，即像素的灰度强度值。
* 对于二维直方图，我们要考虑两个特征。通常，它用于查找颜色直方图，其中两个特征是每个像素的色相和饱和度值。其参数将进行如下修改：
    * channel = [0,1], 因为我们需要同时处理 H 和 S 平面。
    * bins = [180,256] 对于 H 平面为 180，对于 S 平面为 256。
    * range = [0,180,0,256] 色相值介于 0 和 180 之间，饱和度介于 0 和 256 之间。

看了 color_histogram.py 才明白什么含义。

{% include image.html url="/assets/images/211106-opencv-4.1.2/20211113021751.png" %}
{% include image.html url="/assets/images/211106-opencv-4.1.2/20211113021819.png" url2="/assets/images/211106-opencv-4.1.2/20211113021859.png" %}

```python
small = cv.pyrDown(frame)

hsv = cv.cvtColor(small, cv.COLOR_BGR2HSV)
dark = hsv[...,2] < 32
hsv[dark] = 0
# channel = [0,1]，因为我们需要同时处理 H 和 S 平面。
# bins = [180,256] 对于 H 平面为 180，对于 S 平面为 256。
# range = [0,180,0,256] 色相值介于 0 和 180 之间，饱和度介于 0 和 256 之间。
h = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])

h = np.clip(h*0.005*self.hist_scale, 0, 1)
vis = hsv_map*h[:,:,np.newaxis] / 255.0
cv.imshow('hist', vis)
```

GIMP（GNU Image Manipulation Program，GNU 图像处理程序），它是一个图像处理与合成工具。GIMP 的扩展性很强，用户可以通过自己编写的插件来扩充 GIMP 功能。


## [直方图 4：直方图反投影 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484316&idx=1&sn=e7feeec6c3811377c3136fd35b38a314&chksm=fcbbfb66cbcc7270cd23acb3505fc656d50a94a3fd9dd7dffd1504e0be04461dfcc0bfc80fc9&scene=27)

这是由 Michael J. Swain 和 Dana H. Ballard 在他们的论文《通过颜色直方图索引》中提出的。
直方图反投影与 camshift 算法等配合使用。

它用于图像分割或在图像中查找感兴趣的对象。OpenCV 提供了一个内建的函数 cv.calcBackProject()。

```cpp
// 3. 计算公路的直方图
MatND roiHist; // 直方图对象
int dims = 2; // 特征数目（直方图维度）
float hranges[] = { 0, 180 }; // 特征空间的取值范围
float Sranges[] = { 0, 256 };
const float* ranges[] = { hranges, Sranges };
int size[] = { 20, 32 }; // 存放每个维度的直方图的尺寸的数组
int channels[] = {0, 1}; // 通道数
calcHist(&RoiImage_HSV, 1, channels, Mat(), roiHist, dims, size, ranges);
// 4. 直方图归一化
normalize(roiHist, roiHist, 0, 255, NORM_MINMAX);
// 5. 反向投影
Mat proImage; // 投影输出图像
calcBackProject(&HsvImage, 1, channels, roiHist, proImage, ranges);
```

1. 首先，我们需要计算我们要查找的对象（使其为“M”）和要搜索的图像（使其为“I”）的颜色直方图。
```python
import numpy as np
import cv2 as cvfrom matplotlib
import pyplot as plt
# roi 是我们需要找到的对象或对象区域
roi = cv.imread('rose_red.png')
hsv = cv.cvtColor(roi, cv.COLOR_BGR2HSV)
# 目标是我们搜索的图像
target = cv.imread('rose.png')
hsvt = cv.cvtColor(target, cv.COLOR_BGR2HSV)
# 使用 calcHist 查找直方图。也可以使用 np.histogram2d 完成
M = cv.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256] )
I = cv.calcHist([hsvt], [0, 1], None, [180, 256], [0, 180, 0, 256] )
```
2. 求出比值 $R=\frac{M}{T}$。然后反向投影 R，即使用 R 作为调色板，并以每个像素作为其对应的目标概率创建一个新图像。
即 $B(x,y) = R[h(x,y),s(x,y)]$ 其中 h 是色调，s 是像素在 (x,y) 的饱和度。之后，应用条件 $B(x,y) = min[B(x,y), 1]$。
```python
h,s,v = cv.split(hsvt)
B = R[h.ravel(), s.ravel()]
B = np.minimum(B, 1)
B = B.reshape(hsvt.shape[:2])
```
3. 现在对圆盘应用卷积，$B=D∗B$，其中 D 是圆盘内核。
```python
disc = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5,5))
cv.filter2D(B, -1, disc, B)
B = np.uint8(B)
cv.normalize(B, B, 0, 255, cv.NORM_MINMAX)
```
4. 现在最大强度的位置给了我们物体的位置。如果我们期望图像中有一个区域，则对合适的值进行阈值处理将获得不错的结果。
```python
ret, thresh = cv.threshold(B, 50, 255, 0)
```


## [傅里叶变换 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484323&idx=1&sn=390808f61aca7fff6c4a67b08d0512f2&chksm=fcbbfb59cbcc724fd06207d6f0ddb481d9e5089538001f0257798df668371ae8ed82f88ec52b&scene=27)

[from](http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/core/discrete_fourier_transform/discrete_fourier_transform.html)
对一张图像使用傅立叶变换就是将它分解成正弦和余弦两部分。也就是将图像从空间域 (spatial domain) 转换到频域 (frequency domain)。 这一转换的理论基础来自于以下事实：任一函数都可以表示成无数个正弦和余弦函数的和的形式。傅立叶变换就是一个用来将函数分解的工具。 2 维图像的傅立叶变换可以用以下数学公式表达 :

$F(k,l) = \displaystyle\sum\limits_{i=0}^{N-1}\sum\limits_{j=0}^{N-1} f(i,j)e^{-i2\pi(\frac{ki}{N}+\frac{lj}{N})}$

$e^{ix} = \cos{x} + i\sin {x}$

式中 f 是空间域 (spatial domain) 值， F 则是频域 (frequency domain) 值。 转换之后的频域值是复数， 因此，显示傅立叶变换之后的结果需要使用实数图像 (real image) 加虚数图像 (complex image), 或者幅度图像 (magitude image) 加相位图像 (phase image)。 在实际的图像处理过程中，仅仅使用了幅度图像，因为幅度图像包含了原图像的几乎所有我们需要的几何信息。 然而，如果你想通过修改幅度图像或者相位图像的方法来间接修改原空间图像，你需要使用逆傅立叶变换得到修改后的空间图像，这样你就必须同时保留幅度图像和相位图像了。

{% include image.html url="/assets/images/211106-opencv-4.1.2/64023424124.webp" %}
如果您仔细观察结果，尤其是最后一张 JET 颜色的图像，您会看到一些伪像（我用红色箭头标记的一个实例）。
它在那里显示出一些波纹状结构，称为 **振铃效应** 。
这是由我们用于遮罩的矩形窗口引起的。此掩码转换为正弦形状，从而导致此问题。因此，矩形窗口不用于过滤。更好的选择是高斯窗口。

```python
# 没有缩放参数的简单均值滤波器
mean_filter = np.ones((3,3))
# 创建高斯滤波器
x = cv.getGaussianKernel(5,10)
gaussian = x*x.T
# 不同的边缘检测滤波器
# x 方向上的 scharr
scharr = np.array([[-3, 0, 3],
                   [-10,0,10],
                   [-3, 0, 3]])
# x 方向上的 sobel
sobel_x= np.array([[-1, 0, 1],
                   [-2, 0, 2],
                   [-1, 0, 1]])
# y 方向上的 sobel
sobel_y= np.array([[-1,-2,-1],
                   [0, 0, 0],
                   [1, 2, 1]])
# 拉普拉斯变换
laplacian=np.array([[0, 1, 0],
                    [1,-4, 1],
                    [0, 1, 0]])
```

{% include image.html url="/assets/images/211106-opencv-4.1.2/640zzz.webp" %}
为什么拉普拉斯算子是高通滤波器？
从图像中，您可以看到每种内核阻止的频率区域以及它允许经过的区域。从这些信息中，我们可以说出为什么每个内核都是 HPF 或 LPF。
[Fourier Transform](https://homepages.inf.ed.ac.uk/rbf/HIPR2/fourier.htm)


## [模板匹配 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484329&idx=1&sn=3f1c46960705752d38f96a20ab6c5380&chksm=fcbbfb53cbcc7245d78b840d8eb21c056e3e53a54729161f0db84cf383cb932c2564b41bc4b8&scene=27)

cv.matchTemplate()，cv.minMaxLoc()
* 模板匹配 cv2.matchTemplate()；
* 矩阵归一化 cv2.normalize()；
* 寻找最值 cv2.minMaxLoc()。


## [霍夫线变换 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484334&idx=1&sn=cf73840524818ad9d496871f994a1b8a&chksm=fcbbfb54cbcc7242f58c477151df49246f458295464812c9b3df0b45f970fb6798df0b9b0c71&scene=27)

{% include image.html url="/assets/images/211106-opencv-4.1.2/6401615.jpg" %}

检测图像中的线条。
cv.HoughLines()，cv.HoughLinesP()

* 标准霍夫变换、多尺度霍夫变换 cv2.HoughLines() ；
* 累计概率霍夫变换 cv2.HoughLinesP() ；
* 霍夫圆变换 cv2.HoughCricles() 。


## [霍夫圈变换 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484341&idx=1&sn=4bb855c49c123882c81a4eb25beccb45&chksm=fcbbfb4fcbcc7259394ab255dbca9782e7c6aab3dc4e9acb979d16d1ad0b1b191e91c6cdd2d4&scene=27)

霍夫圈变换，查找图像中的圆。
cv.HoughCircles()


## [图像分割与 Watershed 算法 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484346&idx=1&sn=6e2ca509c38839f315f919c8d41076d9&chksm=fcbbfb40cbcc72568a19d1ae99760f83072e9baaf3b665035272669dbf4f6efb45574bc14342&scene=27)

* [OpenCV 分水岭算法 —— watershed 自动图像分割用法 {% include relref_csdn.html %}](https://blog.csdn.net/dcrmg/article/details/52498440)
* [OpenCV 学习 (7) 分水岭算法 (1) {% include relref_cnblogs.html %}](https://www.cnblogs.com/mikewolf2002/p/3304118.html)
* [图像处理 —— 分水岭算法 {% include relref_csdn.html %}](https://blog.csdn.net/fengye2two/article/details/79116105)

图像分割与 Watershed 算法
分水岭算法实现基于标记的图像分割
cv.watershed()

图像修补技术及相关函数 cv2.inpaint()，人像祛斑应用。


## [交互式前景提取使用 GrabCut 算法 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484351&idx=1&sn=48cef8b4146fe32fedafb1d50347593c&chksm=fcbbfb45cbcc7253918294b22d5a868491257e8040359277a0972821bbc2893e28455da74a7b&scene=27)

GrabCut 算法来提取图像中的前景。
OpenCV 示例包含一个示例 catchcut.py，这是一个使用 grabcut 的交互式工具。

* GrabCut 算法 cv2.grabCut()；
* 漫水填充算法 cv2.floodFill()；
* Harris 角点检测 cv2.cornerHarris()；
* Shi-Tomasi 角点检测 cv2.goodFeaturesToTrack()；
* 亚像素角点检测 cv2.cornerSubPix()。


## [理解特征 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484356&idx=1&sn=1be35485e1d3099eca6bb2102ed95d64&chksm=fcbbfb3ecbcc72289548c5c4b1a15f2792d261bf6451858d5093a17a5c7e39eb65db66c61e48&scene=27)


## [哈里斯角检测 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484374&idx=1&sn=6f8ac62b65f7c4998241374b1d4fa3ab&chksm=fcbbfb2ccbcc723a7692f8acf6eaf59bdc87e0544e9e346b2db3fe2948e37328c15e8c161036&scene=27)

哈里斯角检测
cv.cornerHarris(), cv.cornerSubPix()


## [Shi-tomas 拐角检测器和益于跟踪的特征 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484381&idx=1&sn=fa2faa80bea2529df0dca49af976bd16&chksm=fcbbfb27cbcc7231f211d48ea95bd52861468f4d728b63b6559a94321d51d7391a50c65fe287&scene=27)

Shi-tomas 拐角检测器和益于跟踪的特征
cv.goodFeaturesToTrack()


## [SIFT 尺度不变特征变换 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484389&idx=1&sn=d9d56cfc374cca6d14ec107ba614a601&chksm=fcbbfb1fcbcc7209f17d77bfd67f8e641ceb0f5a923a1cb22baa1009b8cb47a299d1e6a6b4ce&scene=27)

SIFT 尺度不变特征变换


## [SURF 简介（加速的强大功能） {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484397&idx=1&sn=18d2975a5c3430bbb06a89fbb8938118&chksm=fcbbfb17cbcc720171a6df6052901d6a3930c25c5facce62a42b87893118709231556e6a902a&scene=27)

SURF 简介（加速的强大功能）


## [用于角点检测的 FAST 算法 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484409&idx=1&sn=588a3cf35e25b9e4bc08d576ef51dc51&chksm=fcbbfb03cbcc7215616c985c29c86ea8793028164d4e75f86406237a143cf7cf38500030bc40&scene=27)


## [BRIEF（二进制的鲁棒独立基本特征） {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484417&idx=1&sn=628fb7001b4e739c8cbd572c6cf6d33b&chksm=fcbbfcfbcbcc75edc92fd60afb5afe5111287c7aee26ec020b153c4bb0b9b927ca90ab418121&scene=27)

BRIEF（二进制的鲁棒独立基本特征）


## [ORB（面向快速和旋转的 BRIEF） {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484426&idx=1&sn=3a2df84201fc930df5d07156b52f1c7a&chksm=fcbbfcf0cbcc75e62cb7f4daf7541adbbdaed8b34b7c77074c4855d871eae3fe3055f6d7faea&scene=27)


## [特征匹配 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484431&idx=1&sn=a835d1062e167a36a542d7d00d5563ba&chksm=fcbbfcf5cbcc75e35afd92357a7bfed8c38d2461174de07a62cf576adf3fbab4905c5c3ed578&scene=27)

FLANN 是近似最近邻的快速库。它包含一组算法，这些算法针对大型数据集中的快速最近邻搜索和高维特征进行了优化。

特征匹配
如何将一个图像中的特征与其他图像进行匹配。

Brute-Force 匹配器和 FLANN 匹配器
{% include image.html url="/assets/images/211106-opencv-4.1.2/6401726.jpg" %}


## [特征匹配 + 单应性查找对象 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484436&idx=1&sn=5bf8a1b04fbe6ffdd4dd28d0da41e95b&chksm=fcbbfceecbcc75f82ee33e81de9f0cc7faac46bb4e1697269436865020d3da8b5ab40a1430dd&scene=27)

把 calib3d 模块中的特征匹配和 findHomography 混合在一起，以在复杂图像中找到已知对象。


## [如何使用背景分离方法 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484441&idx=1&sn=81ef9c260d7e2014ee7cc98d523bcc93&chksm=fcbbfce3cbcc75f568c8afe7b32137af5d06e2e39008c5bf1c493dbd4911e4d37840e791e187&scene=27)

这个是基于视频的。
{% include image.html url="/assets/images/211106-opencv-4.1.2/6401051.png" %}


## [Meanshift 和 Camshift {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484449&idx=1&sn=6b6ab087b4fa3da106001a170653c126&chksm=fcbbfcdbcbcc75cd5cad3684c7ffa868e1b7d56befc4a6ce579f4f1fd1686d94ee19f7df6300&scene=27)

跟踪视频中对象的 Meanshift 和 Camshift 算法。


## [光流 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484486&idx=1&sn=a5cb136af7e319a828133959bc95316a&chksm=fcbbfcbccbcc75aafc1793acb0bd5a9fef951aa3b772a2bb195ff928cb7ce9ff0c09be55c7d2&scene=27)

Lucas-Kanade 方法计算稀疏特征集的光流（在我们的示例中为使用 Shi-Tomasi 算法检测到的角）。OpenCV 提供了另一种算法来查找密集的光流。它计算帧中所有点的光通量。它基于 Gunner Farneback 的算法，在 2003 年 Gunner Farneback 的“基于多项式展开的两帧运动估计”中对此进行了解释。

光流
Lucas-Kanade 方法
使用 cv.calcOpticalFlowPyrLK() 之类的函数来跟踪视频中的特征点。
使用 cv.calcOpticalFlowFarneback() 方法创建一个密集的光流场。


## [相机校准 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484498&idx=1&sn=a8306a8a0cdd2fa6068011c64566c4d5&chksm=fcbbfca8cbcc75be72ce70b92a902f2132c83b6f6a593e32bb2d84231c782be6aa8e75e106f8&scene=27)


## [姿态估计 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484503&idx=1&sn=f5232ce492b11f116d0f631e7e3bb88b&chksm=fcbbfcadcbcc75bb068de10c69b28a7b21e12863909865ddf31f3d8c373232fa2ed6edaf7695&scene=27)

{% include image.html url="/assets/images/211106-opencv-4.1.2/6401056.jfif" %}


## [对极几何 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484509&idx=1&sn=8803d67d41a5524518dbbf24bd7c0a93&chksm=fcbbfca7cbcc75b1832499a80aa536388486b109f06a69901095a170beb3c6c39b3318e85bba&scene=27)

1. 一个重要的主题是相机的前移。然后，将在两个位置的相同位置看到极点，并且从固定点出现极点。请参阅此讨论。
2. 基本矩阵估计对匹配，离群值等的质量敏感。如果所有选定的匹配都位于同一平面上，则情况会变得更糟。检查此讨论。

{% include image.html url="/assets/images/211106-opencv-4.1.2/6401731.jpg" %}


## [立体图像的深度图 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484515&idx=1&sn=2252b058a7b78839fbea7e2a0f5aca46&chksm=fcbbfc99cbcc758fe7f6c99ecab35e47b6048b5a0ced5ac6ed475fd919b70070ec43dff04b0c&scene=27)

{% include image.html url="/assets/images/211106-opencv-4.1.2/6401733.jpg" %}


## [理解 K 近邻 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484520&idx=1&sn=163c907566b42c60c44eba5ca7f4734f&chksm=fcbbfc92cbcc758417af63fb955b703af65215d75106adac0a0fb99697759ccb641a6ac70830&scene=27)

k 近邻（kNN）算法的原理。


## [使用 OCR 手写数据集运行 KNN {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484525&idx=1&sn=3ddc9ae6751d263a895c83ccbe83715e&chksm=fcbbfc97cbcc7581cc6e0a9d6ed85d988643ee80d9479c075b4a87b43f760537badaca64b2b5&scene=27)


## [理解 SVM {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484556&idx=1&sn=415939301ddb1aec8c6066d035ff841a&chksm=fcbbfc76cbcc7560181f489850d09c69c8b659861d59fcf0dfd9b0511f97c3ce769fac35a6ed&scene=27)

SVM 的本质就是画线：所以 SVM 是用来做分类的，而且一条线只能把数据分成两类。


## [使用 OCR 手写数据集运行 SVM {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484561&idx=1&sn=a7e5d55304b124daffb1df6c448fc54c&chksm=fcbbfc6bcbcc757d439bd6e7978d139accf2d2b0b00639f9ed47b3ea89c1d7e1d8778fc8c991&scene=27)


## [理解 K-Means 聚类 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484571&idx=1&sn=7bfabc469365806c5c52d97cbd836dc1&chksm=fcbbfc61cbcc7577ed17e7297b8c8af36f186805d9e2c1c44af615d87df232c79167d874530a&scene=27)

K-Means 的本质就是画圈：所以 K-Means 是一种聚类算法，而且可以画 K 个圈圈分成 K 种类别奥。
<https://zhuanlan.zhihu.com/p/104557021>

常见的一种方法是 elbow method，x 轴为聚类的数量，y 轴为 WSS（within cluster sum of squares）也就是各个点到 cluster 中心的距离的平方的和。
<https://www.zhihu.com/question/29208148>

对于 K-means 中 K 的选择，通常有 [四种方法](http://sofasofa.io/forum_main_post.php?postid=1000282)：
1. 按需选择
2. 观察法
3. 手肘法
4. Gap Statistics 方法


### 使用 scipy 进行层次聚类和 k-means 聚类

**scipy cluster 库简介**
scipy.cluster 是 scipy 下的一个做聚类的 package，共包含了两类聚类方法：
1. 矢量量化 (scipy.cluster.vq)：支持 vector quantization 和 k-means 聚类方法
2. 层次聚类 (scipy.cluster.hierarchy)：支持 hierarchical clustering 和 agglomerative clustering（凝聚聚类）

聚类方法实现：k-means 和 hierarchical clustering。
* <http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html>
* <http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html>
* <http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans.html>
* <http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.vq.html>

[from {% include relref_csdn.html %}](https://blog.csdn.net/elaine_bao/article/details/50242867)
[Programming Computer Vision with Python · 第六章 图像聚类](https://yongyuan.name/pcvwithpython/chapter6.html)


## [图像去噪 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484580&idx=1&sn=7ffd10d6d56b41acded0c0a94e471ed2&chksm=fcbbfc5ecbcc7548c0bb64164dfd56e77e2b70b1dd6cff3f465b2bf40a15ba2e36a259852e14&scene=27)

去除图像中噪声的非局部均值去噪算法。
cv.fastNlMeansDenoising()，cv.fastNlMeansDenoisingColored() 等。
OpenCV 提供了此方法的四个变体。
1. cv.fastNlMeansDenoising() - 处理单个灰度图像
2. cv.fastNlMeansDenoisingColored() - 处理彩色图像。
3. cv.fastNlMeansDenoisingMulti() - 处理在短时间内捕获的图像序列（灰度图像）
4. cv.fastNlMeansDenoisingColoredMulti() - 与上面相同，但用于彩色图像。

* 被高斯噪声污染的图像，用均值滤波处理效果较好；
* 而被椒盐噪声污染的图像，用中值滤波处理效果较好。

NL-Means 的全称是：Non-Local Means，直译过来是非局部平均，该算法使用自然图像中普遍存在的冗余信息来去噪声。
与常用的双线性滤波、中值滤波等利用图像局部信息来滤波不同的是，它利用了整幅图像来进行去噪，
以图像块为单位在图像中寻找相似区域，再对这些区域求平均，能够比较好地去掉图像中存在的高斯噪声。
这种算法比较耗时，但是结果很好。对于彩色图像，要先转换到 CIELAB 颜色空间，然后对 L 和 AB 成分分别去噪。

1. 均值去噪声
1. 高斯模糊去噪声
1. 非局部均值去噪声
1. 双边滤波去噪声
1. 形态学去噪声


## [图像修补 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484586&idx=1&sn=cebc51a5cae4ab7070fd13b6ff0ce179&chksm=fcbbfc50cbcc754614baa28041575aece4aea27bb1d4ea6124c1576fefabcf1b63695346bd30&scene=27)

Content-Aware Fill 是 Adobe Photoshop 中使用的一种先进的修复技术。
在进一步的搜索中，我发现 GIMP 中已经存在相同的技术，但名称不同，为“ Resynthesizer”（你需要安装单独的插件）。
<https://blog.csdn.net/lcbwlx/article/details/18272295> Resythesizer（正确的应该是 Resynthesizer）


## [高动态范围 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484591&idx=1&sn=617d6901161cbfaacd949d55344bc826&chksm=fcbbfc55cbcc754328384190f7d8e0d46716f27448bf6834c541e69f7a6f6b17dc6c8d14216d&scene=27)

了解如何根据曝光顺序生成和显示 HDR 图像。
使用曝光融合来合并曝光序列。


## [级联分类器 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484596&idx=1&sn=80eabb75c2599f94c73b2e9604adcb08&chksm=fcbbfc4ecbcc755850551eade69b3a7966d05a60edaf69effd8f97640553931e6223faf489a4&scene=27)


## [级联分类器训练 {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484601&idx=1&sn=86ae2205986c9e324828f650376136a5&chksm=fcbbfc43cbcc7555bfb0ec7d879426a03600219b89b3e6849cca5799ec2abc7b3ef4a88f9395&scene=27)


## [OpenCV-Python Bindings 如何工作？ {% include relref_weixin.html %}](http://mp.weixin.qq.com/s?__biz=MzU2NTUwNjQ1Mw==&mid=2247484627&idx=1&sn=9334cfd3e30bc35395c964b670b2478f&chksm=fcbbfc29cbcc753f64a22fee16f982a945f2bbedee7d26df638dcf2d1c4564d9f590acbfa658&scene=27)


## Refs

深度学习与计算机视觉
微信号 `uncle_pn`


## [x 系列](https://docs.opencv.org/4.5.3/d2/d75/namespacecv.html)


### cv::xfeatures2d


### cv::ximgproc

opencv 中的 cv::ximgproc::SuperpixelSLIC, cv::ximgproc::SuperpixelSEEDS, SuperpixelLSC 是超像素算法的

检测直线（利用 cv::ximgproc::FastLineDetector）
ximgproc 图像处理模块。包含结构森林，变化域滤波器，导向滤波，自适应流行滤波器，联合双边滤波器和超像素。
[from](https://www.freesion.com/article/2320381568/)
{% include image.html url="/assets/images/211106-opencv-4.1.2/4751243a286f6f0ccc66397da532a340.png" %}


### cv::xphoto

xphoto 是一个 white balance namespace，opencv 自带了三种白平衡的算法



<hr class='reviewline'/>
<p class='reviewtip'><script type='text/javascript' src='{% include relref.html url="/assets/reviewjs/blogs/2021-11-06-opencv-4.1.2.md.js" %}'></script></p>
<font class='ref_snapshot'>参考资料快照</font>

- [https://docs.opencv.org/4.1.2/d6/d00/tutorial_py_root.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/docs.opencv.org/45dd6044.html" %})
- [https://www.bookstack.cn/read/opencv-doc-zh-4.0/README.md]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/www.bookstack.cn/5d61fad3.html" %})
- [https://github.com/oneapi-src/oneTBB]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/github.com/acfc8855.html" %})
- [http://pages.cs.wisc.edu/~csverma/CS766_09/ImageMosaic/imagemosaic.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/pages.cs.wisc.edu/61b3b8fc.html" %})
- [https://mp.ofweek.com/bigdata/a145693523076]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/mp.ofweek.com/a628854e.html" %})
- [http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/core/discrete_fourier_transform/discrete_fourier_transform.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/www.opencv.org.cn/77cbfc0c.html" %})
- [https://homepages.inf.ed.ac.uk/rbf/HIPR2/fourier.htm]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/homepages.inf.ed.ac.uk/0ef17650.htm" %})
- [https://blog.csdn.net/dcrmg/article/details/52498440]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/blog.csdn.net/0ec84380.html" %})
- [https://www.cnblogs.com/mikewolf2002/p/3304118.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/www.cnblogs.com/b1852050.html" %})
- [https://blog.csdn.net/fengye2two/article/details/79116105]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/blog.csdn.net/bd913dfd.html" %})
- [https://zhuanlan.zhihu.com/p/104557021]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/zhuanlan.zhihu.com/db5dace6.html" %})
- [https://www.zhihu.com/question/29208148]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/www.zhihu.com/f42cc13c.html" %})
- [http://sofasofa.io/forum_main_post.php?postid=1000282]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/sofasofa.io/b7578f57.php" %})
- [http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/docs.scipy.org/dbe0fe48.html" %})
- [http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.fcluster.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/docs.scipy.org/d030f037.html" %})
- [http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/docs.scipy.org/94d4dd60.html" %})
- [http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.vq.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/docs.scipy.org/5f141f67.html" %})
- [https://blog.csdn.net/elaine_bao/article/details/50242867]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/blog.csdn.net/80ecb162.html" %})
- [https://yongyuan.name/pcvwithpython/chapter6.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/yongyuan.name/5720343d.html" %})
- [https://blog.csdn.net/lcbwlx/article/details/18272295]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/blog.csdn.net/1c0690aa.html" %})
- [https://docs.opencv.org/4.5.3/d2/d75/namespacecv.html]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/docs.opencv.org/87b7fdbd.html" %})
- [https://www.freesion.com/article/2320381568/]({% include relrefx.html url="/backup/2021-11-06-opencv-4.1.2.md/www.freesion.com/79d0d08b.html" %})
